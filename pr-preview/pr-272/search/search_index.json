{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>RDycore is a performance-portable, GPU-capable river model used to study compound flooding, intended for use with the Department of Energy's Energy Exascale Earth System Model (E3SM).</p> <ul> <li>The Installation Guide shows you how to build and install   RDycore on your own machine or on a supported high-performance platform.</li> <li>The User Guide describes how to use RDycore in its standalone and   E3SM-integrated forms.</li> <li>The Developer Guide lays out some basic principles and   guidelines we use in developing RDycore.</li> </ul>"},{"location":"index.html#acknowledgements","title":"Acknowledgements","text":"<p>RDycore is funded by the US Department of Energy's (DOE) Scientific Discovery Through Advanced Computing (SciDAC) program through a joint partnership between the DOE Office of Science's Biological and Environmental Research and Advanced Scientific Computing Research programs.</p>"},{"location":"common/input.html","title":"RDycore YAML Input Specification","text":"<p>You can configure an RDycore simulation by creating a text file that uses the YAML markup language. Typically, these files have a <code>.yml</code> or <code>.yaml</code> suffix like <code>ex2b.yaml</code>. In this section, we describe how to express the specifics for your simulation using the YAML syntax.</p> <p>Before a YAML file is parsed, RDycore performs some string substitutions to allow certain parameters to be used, e.g. for setting the names of data files based on different build configurations. The following table lists the patterns that are replaced, and the substitutions that replace them.</p> Pattern Substitution <code>${PETSC_ID_TYPE}</code> <code>int32</code> or <code>int64</code> based on whether PETSc is built with 64-bit indices <p>RDycore's YAML input is broken up into several sections, each responsible for a different aspect of the desired simulation. These sections fall into several broad categories:</p> <ul> <li>Model equations and discretizations<ul> <li>physics: configures the different physical models   represented within RDycore</li> <li>numerics: specifies the numerical methods used   to solve the model equations</li> <li>grid: defines RDycore's discrete computational domain</li> <li>regions: associates regions (disjoint sets of cells)   defined in a grid file with human-readable names</li> <li>boundaries: associates boundaries (disjoint sets of   edges) defined in a grid file with human-readable names</li> <li>time: defines the timespan for the simulation, sets   limits and units for time stepping</li> </ul> </li> <li>Simulation diagnostics, output, and restarts<ul> <li>logging: controls informational messages logged to   files or to the terminal</li> <li>output: configures simulation output, including   scalable I/O formats and related parameters</li> <li>checkpoint: configures simulation checkpoint   files, which are used for restarts</li> <li>restart: configures whether a simulation is restarted   from a previously saved checkpoint file</li> </ul> </li> <li>Material properties<ul> <li>materials: defines the materials available to   the simulation</li> <li>surface_composition: associates   materials defined in the <code>materials</code> section with files in which the   relevant material properties are stored</li> </ul> </li> <li>Initial and boundary conditions, source terms<ul> <li>initial_conditions: associates initial   conditions (as defined in <code>flow_conditions</code>, <code>sediment_conditions</code>, and/or   <code>salinity_conditions</code>) with specific regions defined in the <code>regions</code>   section</li> <li>sources: associates source contributions   (as defined in <code>flow_conditions</code>, <code>sediment_conditions</code>, and/or   <code>salinity_conditions</code>) with specific regions defined in the <code>regions</code>   section</li> <li>boundary_conditions: associates boundary   conditions (as defined in <code>flow_conditions</code>, <code>sediment_conditions</code>, and/or   <code>salinity_conditions</code>) with specific boundaries defined in the   <code>boundaries</code> section</li> <li>flow_conditions: defines flow-related   parameters that can be used to specify initial/boundary conditions and   sources</li> <li>sediment_conditions: defines sediment-related   parameters that can be used to specify initial/boundary conditions and   sources</li> <li>salinity_conditions: defines salinity-related   parameters that can be used to specify initial/boundary conditions and   sources</li> </ul> </li> <li>Running Ensembles<ul> <li>ensemble: defines sets of parameters that vary   between ensemble members so RDycore can run several simulations at once</li> </ul> </li> </ul> <p>Each of these sections is described below, with a motivating example.</p>"},{"location":"common/input.html#boundaries","title":"<code>boundaries</code>","text":"<pre><code>boundaries:\n  - name: top_wall\n    grid_boundary_id: 2\n  - name: bottom_wall\n    grid_boundary_id: 3\n  - name: exterior\n    grid_boundary_id: 1\n</code></pre> <p>The <code>boundaries</code> section is a sequence (list) of boundary definitions, each of which contains the following parameters:</p> <ul> <li><code>name</code>: a human-readable name for the boundary</li> <li><code>grid_boundary_id</code>: an integer identifier associated with a disjoint set of   grid edges. If this identifier is not found within the grid file specified   in the <code>grid</code> section, a fatal error occurs.</li> </ul> <p>Boundary definitions can appear in any order within the sequence. The <code>boundaries</code> section is optional, and need not be specified if you don't need to associate a specific boundary condition with a specific boundary.</p>"},{"location":"common/input.html#boundary_conditions","title":"<code>boundary_conditions</code>","text":"<pre><code>boundary_conditions:\n  - boundaries: [top_wall]\n    flow: reflecting_bc\n  - boundaries: [bottom_wall]\n    flow: outflow_bc\n</code></pre> <p>The <code>boundary_conditions</code> section is a sequence (list) associating <code>flow</code>, <code>sediment</code>, and <code>salinity</code> conditions (as defined in their respective sections) with boundaries (as defined in the <code>boundaries</code> section). A boundary can have at most one set of boundary conditions associated with it, but a boundary condition can be associated with multiple boundaries, as indicated by the <code>boundaries</code> field, which accepts a list of boundary names. If no boundary conditions are given for a specific boundary, that boundary is assigned an automatically-generated reflecting boundary condition and homogeneous Neumann sediment and salinity conditions.</p> <p>The above example shows a valid configuration for a simulation in which sediments and salinity are not modeled, so only the <code>flow</code> parameter is required. The presence of sediment boundary concentrations requires the <code>sediment</code> parameter, as the presence of salinity concentrations requires the <code>salinity</code> parameter.</p> <p>Like the <code>boundaries</code> section, the <code>boundary_conditions</code> section is optional. If no boundary conditions are specified, all boundaries are assumed to have a reflecting boundary condition.</p>"},{"location":"common/input.html#checkpoint","title":"<code>checkpoint</code>","text":"<pre><code>checkpoint:\n  format: hdf5\n  interval: 100\n</code></pre> <p>The <code>checkpoint</code> section contains fields that specify whether and how RDycore writes checkpoint files, which can be used to restart simulations using parameters in the <code>restart</code> section.</p> <ul> <li><code>format</code>: the format of the checkpoint files to be written. This can be either   <code>binary</code> (the default) or <code>hdf5</code>.</li> <li><code>interval</code>: the number of time steps taken between writing checkpoint files.   This must be a positive integer.</li> <li><code>prefix</code>: an optional prefix for checkpoint files. If omitted, the prefix for   checkpoint files is the prefix of the YAML input file name for the simulation.</li> </ul> <p>The name of a checkpoint file written at time step <code>N</code> is <code>&lt;prefix&gt;.rdycore.r.&lt;N&gt;.&lt;format&gt;</code>, where <code>&lt;prefix&gt;</code> is the checkpoint prefix and <code>&lt;format&gt;</code> is <code>bin</code> for a binary file and <code>h5</code> for an HDF5 file.</p> <p>This section is optional. If omitted, no checkpoint files are written.</p>"},{"location":"common/input.html#ensemble","title":"<code>ensemble</code>","text":"<pre><code>ensemble:\n  size: 3\n  members:\n  - name: member0\n    materials:\n    - name: smooth\n      properties:\n        manning:\n          value: 0.15\n  - name: member1\n    materials:\n    - name: smooth\n      properties:\n        manning:\n          value: 0.20\n  - name: member2\n    materials:\n    - name: smooth\n      properties:\n        manning:\n          value: 0.25\n    flow_conditions:\n    - name: domain_flow_ic\n      type: dirichlet\n      file: Differnt.Houston1km.ic.${PETSC_ID_TYPE}.bin\n      format: binary\n</code></pre> <p>The <code>ensemble</code> section defines parameter sets used to construct an ensemble of simulations with different parameters.</p> <p>Currently, this section lists all ensemble members, each with specific parameters overridden. This explicit approach to constructing ensembles allows the parameter sampling procedure to be performed by external tools. Here are the fields of the <code>ensemble</code> section:</p> <ul> <li><code>size</code>: the number of ensemble members. This parameter is redundant in the   sense that the number of ensemble members can be determined by the <code>members</code>   field (below), but RDycore throws an error if the actual number of members   does not match this parameter.</li> <li><code>members</code>: a list of ensemble members, specified using YAML's sequence syntax   (<code>-</code>). An ensemble member is just a collection of sections containing   overridden parameters. An optional <code>name</code> field provides a name for each   ensemble member; if omitted, the ensemble is automatically named in   relation to its index within the list of members.</li> </ul> <p>Use the syntax (<code>-</code>) to add a member to the ensemble's <code>members</code> field. The member consists of a set of sections with specific overridden parameters. Sections that can be overridden in an ensemble member are:</p> <ul> <li><code>grid</code></li> <li><code>materials</code></li> <li><code>flow_conditions</code></li> <li><code>sediment_conditions</code></li> <li><code>salinity_conditions</code></li> </ul> <p>The example above redefines the Manning coefficient of the <code>smooth</code> material defined elsewhere in the file. In plain language, the example varies the smoothness of the <code>smooth</code> material between ensemble members. Additionally, the file used to initialize the <code>domain_flow_ic</code> condition is overridden for the third member (<code>member2</code>).</p> <p>This syntax is a bit cumbersome for assembling ensembles by hand, but it's a simple mechanism for overriding parameters within ensemble members without creating any new syntax for simulation input.</p>"},{"location":"common/input.html#flow_conditions","title":"<code>flow_conditions</code>","text":"<pre><code>flow_conditions:\n  - name: dam_top_ic\n    type: dirichlet\n    height: 10\n    x_momentum: 0\n    y_momentum: 0\n  - name: dam_bottom_ic\n    type: dirichlet\n    file: dam_ics.dat\n    format: binary\n  - name: reflecting_bc\n    type: reflecting\n  - name: outflow_bc\n    type: critical-outflow\n</code></pre> <p>The <code>flow_conditions</code> section contains a sequence of sets of parameters defining flow within a cell or cell boundary (edge). These flow conditions can be used to define initial conditions, source contributions, and boundary conditions elsewhere in the file. The parameters that define a flow condition are</p> <ul> <li><code>name</code>: a human-readable name that can be used to refer to this flow condition</li> <li><code>type</code>: the type of constraint applied by this flow condition. Available   options are<ul> <li><code>dirichlet</code>: the condition explicitly specifies the value of relevant   flow variables. This is useful for Dirichlet boundary conditions,   initial conditions, and source terms.</li> <li><code>neumann</code>: the condition explicitly specifies the value of the directional   derivative of relevant flow variables on cell boundaries. This is useful   only for boundary conditions. Currently, only homogeneous Neumann conditions   are supported.</li> <li><code>reflecting</code>: the condition specifies that no flow occurs through a given   boundary, and that the boundary reflects the momentum contained in the flow.   Useful only for boundary conditions.</li> <li><code>critical-outflow</code>: the condition specifies that flow through a boundary   is defined by a critical outflow condition. Useful only for boundary   conditions.</li> </ul> </li> </ul> <p>In the case of a Dirichlet condition, flow is prescribed by providing parameters to set the water height and momentum. This can be done in one of two ways:</p> <ol> <li> <p>By specifying the parameters directly using the following fields:</p> <ul> <li><code>height</code>: the height of water [m] at the relevant point (within a cell   or on its boundary)</li> <li><code>x_momentum</code>: the <code>x</code> component of the momentum [kg m/s] at the relevant   point (within a cell or on its boundary)</li> <li><code>y_momentum</code>: the <code>y</code> component of the momentum [kg m/s] at the relevant   point (within a cell or on its boundary)</li> </ul> </li> <li> <p>By specifying a file from which data for these parameters is to be read. The    data is read into the components of the solution vector that correspond    to the cells belonging to the region to which this flow condition is    assigned:</p> </li> <li> <p><code>file</code>: the path for the file from which data is read, specified relative      to the directory in which the RDycore executable was run.</p> </li> <li><code>format</code>: the format of the data in the file, which current must be      <code>binary</code> (specifying PETSc's binary format).</li> </ol>"},{"location":"common/input.html#grid","title":"<code>grid</code>","text":"<pre><code>grid:\n  file: breaking-dam.exo\n</code></pre> <p>The <code>grid</code> section defines the computational domain used by RDycore. Currently, has only a single parameter:</p> <ul> <li><code>file</code>: the file containing the grid representing the computational domain.   This grid must be stored in a format supported by PETSc's DMPlex   data structure.</li> </ul>"},{"location":"common/input.html#initial_conditions","title":"<code>initial_conditions</code>","text":"<pre><code>initial_conditions:\n  - region: upstream\n    flow: dam_top_ic\n  - region: downstream\n    flow: dam_bottom_ic\n</code></pre> <p>The <code>initial_conditions</code> section is a sequence (list) associating <code>flow</code>, <code>sediment</code>, and <code>salinity</code> conditions (as defined in their respective sections) with regions (as defined in the <code>regions</code> section). A region must have exactly one set of initial conditions associated with it. The above example shows a valid configuration for a simulation in which sediments and salinity are not modeled, so only the <code>flow</code> parameter is required. The presence of sediment concentrations requires the <code>sediment</code> parameter, as the presence of salinity concentrations requires the <code>salinity</code> parameter.</p>"},{"location":"common/input.html#logging","title":"<code>logging</code>","text":"<pre><code>logging:\n  file: rdycore.log\n  level: info\n</code></pre> <p>The <code>logging</code> section controls how messages emitted by RDycore are logged. The relevant parameters in this section are</p> <ul> <li><code>file</code>: the file to which logged messages are written, relative to the   directory in which RDycore (coupled or uncoupled) is executed. If this   parameter is omitted, logged messages are written to standard output.</li> <li><code>level</code>: the desired level of detail that determines which messages are   logged. Available options are<ul> <li><code>none</code>: no messages are logged</li> <li><code>warning</code>: only warnings/urgent messages are logged</li> <li><code>info</code>: warnings and informational messages are logged</li> <li><code>detail</code>: warnings, informational messages, and messages with some   degree of technical detail are logged</li> <li><code>debug</code>: all messages including debugging prints are logged</li> </ul> </li> </ul>"},{"location":"common/input.html#materials","title":"<code>materials</code>","text":"<pre><code>materials:\n  - name: smooth\n    properties:\n      manning:\n        value: 0.15\n  - name: rough\n    properties:\n      manning:\n        file: rough-manning.dat\n        format: binary\n</code></pre> <p>The <code>materials</code> section is a sequence (list) of named materials defined by specific material properties. Each material is essentially a named list of material properties specified either directly by value or by data in a specific file with a specific format. A material itself is specified by the following fields:</p> <ul> <li><code>name</code>: a human-readable name that can be used to refer to a material</li> <li><code>properties</code>: a mapping of material properties, with property names   mapped to one or more of the following fields:<ul> <li><code>value</code>: the value of the material property (omitted when <code>file</code> is specified)</li> <li><code>file</code>: the name of a file from which the property is to be read (omitted when <code>value</code> is specified)</li> <li><code>format</code>: the format of the specified file (if any)</li> </ul> </li> </ul> <p>Valid material properties are:</p> <ul> <li><code>manning</code> (required): the value of the Manning roughness coefficient   for the material</li> </ul>"},{"location":"common/input.html#numerics","title":"<code>numerics</code>","text":"<pre><code>numerics:\n  spatial: fv\n  temporal: euler\n  riemann: roe\n</code></pre> <p>The <code>numerics</code> section defines the spatial and temporal discretizations used by RDycore. The parameters that define these discretizations are</p> <ul> <li><code>spatial</code>: determines the spatial discretization. Can be either <code>fv</code> for   a finite volume method, or <code>fe</code> for a finite element method. Currently, only   <code>fv</code> is implemented. Default value: <code>fv</code></li> <li><code>temporal</code>: determines the method of time integration used. Can be <code>euler</code>   for the forward Euler method, <code>rk4</code> for a 4th-order Runge-Kutta method, or   <code>beuler</code> for the L-stable backward Euler method. Currently, only <code>euler</code> and   <code>rk4</code> are supported. Default value: <code>euler</code></li> <li><code>riemann</code>: determines the form of the Riemann solver used for the shallow   water equations. Can be <code>roe</code> for the Roe solver or <code>hllc</code> for the HLLC solver.   Currently, only <code>roe</code> is implemented. Default value: <code>roe</code></li> </ul>"},{"location":"common/input.html#output","title":"<code>output</code>","text":"<pre><code>output:\n  directory: output\n  format: xdmf\n  step_interval: 100\n  batch_size: 1\n  time_series:\n    boundary_fluxes: 10\n  separate_grid_file: true\n</code></pre> <p>The <code>output</code> section control simulation output, including visualization and time series data (and excluding checkpoint data). Relevant parameters are</p> <ul> <li><code>directory</code>: the name of the directory to which output is written. It can be a relative or absolute path, and is created if it doesn't already exist. Default value: <code>output</code></li> <li><code>format</code>: the format of the output written. Available options are<ul> <li><code>none</code>: no output is written. This is the default value.</li> <li><code>binary</code>: output is written using PETSc's binary data format</li> <li><code>xdmf</code>: output is written to the XDMF format</li> <li><code>cgns</code>: output is written to the CFD General Notation System (CGNS) format</li> </ul> </li> <li><code>step_interval</code>: the number of time steps between output dumps. Default value: 0 (no output)</li> <li><code>time_interval</code>: the temporal frequency between output dumps. The is an integer with a minimum value of 1 second. Default value: 0 (no output)</li> <li><code>time_unit</code>: units of temporal frequency output.</li> <li><code>batch_size</code>: the number of time steps for which output data is stored in a   single file. For example, a batch size of 10 specifies that each individual   output file stores data for 10 time steps. Default value: 1</li> <li><code>time_series</code>: this subsection controls time series simulation output, which   is useful for inspection and possibly even coupling. Currently, this subsection   has only one parameter:<ul> <li><code>boundary_fluxes</code>: the interval (number of timesteps) at which boundary   flux data is appended to a tab-delimited text file</li> </ul> </li> <li><code>separate_grid_file</code>: this optional parameter specifies whether the grid is   written to its own file, which saves space in very large simulations. Currently,   this option is only supported for <code>xdmf</code> output.</li> </ul>"},{"location":"common/input.html#physics","title":"<code>physics</code>","text":"<pre><code>physics:\n  flow:\n    mode: swe\n    tiny_h: 1e-7\n    h_anuga_regular: 1.e-3\n    source:\n      method: implicit_xq2018\n      xq2018_threshold: 1e-10\n  sediment:\n    num_classes: 1\n  salinity: false\n</code></pre> <p>The <code>physics</code> section determines which model physics are active in RDycore. There are three available physical models.</p> <p>First is the flow model, which is configured in the <code>flow</code> subsection. This model determines how flooding is represented within RDycore. The relevant parameters in this subsection are:</p> <ul> <li><code>mode</code>, which determines how the height of floodwater is computed. Valid    parameters are <code>swe</code> (shallow water equations)    and <code>diffusive</code> (diffusive wave approximation,    not yet supported). This parameter is required and has no default value.</li> <li><code>tiny_h</code>, which is the water height below which a given point is assumed to   be dry. Default value: <code>1e-7</code></li> <li><code>h_anuga_regular</code>: is the water height used in velocity regularization using the   approach implemented in the ANUGA hydrodynamic model. e.g., the velocity in x-dir from the   momentum in x-dir is computed as <code>u = (hu) * h / (h^2 + h_anuga_regular^2)</code>. The   default value is <code>0.0</code>.</li> <li><code>source</code>: this subsection controls parameters governing how the flow source   term is integrated in time. Parameters are:</li> <li><code>method</code>: the method for integrating the flow source term. Options are<ul> <li><code>semi_implicit</code>: a semi-implicit source treatment (default value)</li> <li><code>implicit_xq2018</code>: a fully implicit source treatment based on Xilin and Qiuhua (2018)</li> </ul> </li> <li><code>xq2018_threshold</code>: threshold for the implicit integration of the source     (valid only for the <code>implicit_xq2018</code> method; default value: <code>1e-10</code>)</li> </ul> <p>The second physical model is the sediment dynamics model, which evolves the concentrations of distinct size classes of sediments. You can set the number of size classes with the <code>num_classes</code> parameter (default value: <code>0</code>). Disable sediment dynamics by setting <code>num_classes</code> to <code>0</code>.</p> <p>The third physical model is the salinity model, which you can also enable or disable this by setting the <code>salinity</code> parameter to <code>true</code> or <code>false</code>.</p>"},{"location":"common/input.html#regions","title":"<code>regions</code>","text":"<pre><code>regions:\n  - name: upstream\n    grid_region_id: 2\n  - name: downstream\n    grid_region_id: 1\n</code></pre> <p>The <code>regions</code> section is a sequence (list) of regions definitions, each of which contains the following parameters:</p> <ul> <li><code>name</code>: a human-readable name for the boundary</li> <li><code>grid_region_id</code>: an integer identifier associated with a disjoint set of   grid cells. If this identifier is not found within the grid file specified   in the <code>grid</code> section, a fatal error occurs.</li> </ul> <p>Region definitions can appear in any order within the sequence.</p>"},{"location":"common/input.html#restart","title":"<code>restart</code>","text":"<pre><code>restart:\n  file: checkpoint-100.h5\n  reinitialize: true\n</code></pre> <p>The <code>restart</code> section allows a user to specify a checkpoint file from which a simulation is restarted.</p> <ul> <li><code>file</code>: the name of the checkpoint file from which to restart the simulation</li> <li><code>reinitialize</code>: a flag indicating whether to reinitialize the simulation time   to 0 (<code>true</code>) or continue from the time at which the checkpoint file was   written (<code>false</code>)</li> </ul>"},{"location":"common/input.html#salinity_conditions","title":"<code>salinity_conditions</code>","text":"<pre><code>salinity_conditions:\n  - name: my-sal-condition\n    type: dirichlet\n    concentration: 1\n</code></pre> <p>The <code>salinity_conditions</code> section contains a sequence of sets of parameters defining the salinity concentration within a cell or cell boundary (edge). A salinity condition can be used to define initial conditions, source contributions, and boundary conditions elsewhere in the file. The parameters that define a salinity condition are</p> <ul> <li><code>name</code>: a human-readable name that can be used to refer to the salinity condition</li> <li><code>type</code>: the type of constraint applied by this salinity condition. Available   options are<ul> <li><code>dirichlet</code>: the condition explicitly specifies the value of the   salinity concentration. This is useful for Dirichlet boundary conditions,   initial conditions, and source terms.</li> <li><code>neumann</code>: the condition explicitly specifies the value of the directional   derivative of the concentration on cell boundaries. This is useful   only for boundary conditions. Currently, only homogeneous Neumann conditions   are supported.</li> </ul> </li> </ul> <p>In the case of a Dirichlet condition, a salinity concentration is prescribed by providing one or more parameters. This can be done in one of two ways:</p> <ol> <li> <p>By specifying the concentration directly using the <code>concentration</code> parameter</p> </li> <li> <p>By specifying a file from which concentration data is to be read. The    data is read into the components of the solution vector that correspond    to the cells belonging to the region to which this flow condition is    assigned:</p> </li> <li> <p><code>file</code>: the path for the file from which data is read, specified relative      to the directory in which the RDycore executable was run.</p> </li> <li><code>format</code>: the format of the data in the file, which current must be      <code>binary</code> (specifying PETSc's binary format).</li> </ol>"},{"location":"common/input.html#sediment_conditions","title":"<code>sediment_conditions</code>","text":"<pre><code>sediment_conditions:\n  - name: my-sed-condition\n    type: dirichlet\n    concentration: 1\n</code></pre> <p>The <code>sediment_conditions</code> section contains a sequence of sets of parameters defining the sediment concentration within a cell or cell boundary (edge). A sediment condition can be used to define initial conditions, source contributions, and boundary conditions elsewhere in the file. The parameters that define a sediment condition are</p> <ul> <li><code>name</code>: a human-readable name that can be used to refer to the sediment condition</li> <li><code>type</code>: the type of constraint applied by this sediment condition. Available   options are<ul> <li><code>dirichlet</code>: the condition explicitly specifies the value of the   sediment concentration. This is useful for Dirichlet boundary conditions,   initial conditions, and source terms.</li> <li><code>neumann</code>: the condition explicitly specifies the value of the directional   derivative of the sediment concentration on cell boundaries. This is   useful only for boundary conditions. Currently, only homogeneous Neumann   conditions are supported.</li> </ul> </li> </ul> <p>In the case of a Dirichlet condition, a sediment concentration is prescribed by providing one or more parameters. This can be done in one of two ways:</p> <ol> <li> <p>By specifying the concentration directly using the <code>concentration</code> parameter</p> </li> <li> <p>By specifying a file from which concentration data is to be read. The    data is read into the components of the solution vector that correspond    to the cells belonging to the region to which this flow condition is    assigned:</p> </li> <li> <p><code>file</code>: the path for the file from which data is read, specified relative      to the directory in which the RDycore executable was run.</p> </li> <li><code>format</code>: the format of the data in the file, which current must be      <code>binary</code> (specifying PETSc's binary format).</li> </ol>"},{"location":"common/input.html#sources","title":"<code>sources</code>","text":"<pre><code>sources:\n  - region: upstream\n    flow: dam_top_src\n  - region: downstream\n    flow: dam_bottom_src\n</code></pre> <p>The <code>sources</code> section is a sequence (list) associating <code>flow</code>, <code>sediment</code>, and <code>salinity</code> sources (as defined in their respective sections) with regions (as defined in the <code>regions</code> section). Sources are optional for each region--if omitted, a region has no source contributions. A region may have no more than one set of source conditions associated with it. The above example shows a valid configuration for a simulation in which sediments and salinity are not modeled, so only the <code>flow</code> parameter is required. The presence of sediment sources requires the <code>sediment</code> parameter, as the presence of salinity sources requires the <code>salinity</code> parameter.</p>"},{"location":"common/input.html#surface_composition","title":"<code>surface_composition</code>","text":"<pre><code>surface_composition:\n  - region: upstream\n    material: smooth\n  - region: downstream\n    material: rough\n</code></pre> <p>The <code>surface_composition</code> section is a sequence (list) associating materials (as defined in the <code>materials</code> section) with regions (as defined in the <code>regions</code> section). Since regions and materials both have human-readable names, the association between the two is made clear by the <code>region</code> and <code>material</code> parameters in each entry. A region is understood to be completely filled with the material with which it is associated--the relationship between regions and materials is necessarily 1:1.</p>"},{"location":"common/input.html#time","title":"<code>time</code>","text":"<pre><code>time:\n  final_time: 1\n    unit: years\n    max_step: 1000\n    time_step: 0.001\n    coupling_interval: 0.01\n</code></pre> <p>The <code>time</code> section determines the time-stepping strategy used by RDycore using the following parameters:</p> <ul> <li><code>units</code>: the units in which time is expressed in the input file. Available   options are <code>seconds</code>, <code>minutes</code>, <code>hours</code>, <code>days</code>, <code>months</code>, and <code>years</code>.   This parameter is required and has no default value.</li> <li><code>final_time</code>: the time at which the simulation ends (in the desired units)</li> <li><code>max_step</code>: the number of steps after which the simulation ends</li> <li><code>time_step</code>: a fixed size used for the time step in the desired units.</li> <li><code>coupling_inverval</code>: the time interval (in the desired units) at which   RDycore advances without coupling to E3SM. By default, RDycore runs a single   time step without coupling to E3SM.</li> </ul> <p>Exactly two of <code>final_time</code>, <code>max_step</code>, and <code>time_step</code> must be specified. The missing parameter is then computed from those parameters given.</p> <p>Additionally, RDycore can increase or decrease time step to meet a target Courant number via <code>adaptive</code> sub-block within the <code>time</code> block as shown below.</p> <pre><code>time:\n  final_time        : 0.005\n  coupling_interval : 0.001\n  unit              : hours\n  adaptive:\n    enable                 : true     # false or true. The values below are only used if is enable=true\n    target_courant_number  : 0.6      # a target courant number\n    max_increase_factor    : 2        # At max, the dt can be doubled to meet the target Courant number\n    initial_time_step      : 0.00001  # initial timestep\n</code></pre> <p>The time step is increased/decreased used by <code>TS</code> at the coupling internal. The global Courant number during the last step of a <code>TSSolve</code> is used to either increase or decrease the time step for the next <code>TSSolve</code> to match the target Courant number (<code>target_cournant_number</code>). When time step adaptive is enabled (via <code>enable: true</code>), the <code>max_step</code> and <code>time_step</code> entried within the <code>time</code> block cannot be specified. Instead, one need to specify an initial time step (<code>initial_time_step</code>) in the <code>adaptive</code> sub-block.</p>"},{"location":"common/installation.html","title":"Installation","text":"<p>You can build and run RDycore on the following platforms:</p> <ul> <li>Linux and Mac laptops and workstations</li> <li>Frontier (Oak Ridge National Laboratory)</li> <li>Perlmutter (NERSC)</li> </ul>"},{"location":"common/installation.html#required-software","title":"Required Software","text":"<p>To build RDycore, you need:</p> <ul> <li>CMake v3.14+</li> <li>GNU Make</li> <li>reliable C, C++, and Fortran compilers</li> <li>a working MPI installation (like OpenMPI   or MPICH)</li> <li>PETSc, built with the following third-party   libraries:<ul> <li>cgns</li> <li>exodusii</li> <li>fblaslapack</li> <li>hdf5</li> <li>libceed</li> <li>metis</li> <li>muparser</li> <li>netcdf</li> <li>parmetis</li> <li>pnetcdf</li> <li>zlib</li> </ul> </li> </ul> <p>You can obtain all of these freely on the Linux and Mac platforms. On Linux, just use your favorite package manager. On a Mac, you can get the Clang C/C++ compiler by installing XCode, and then use a package manager like Homebrew or MacPorts to get the rest.</p>"},{"location":"common/installation.html#which-version-of-petsc","title":"Which version of PETSc?","text":"<p>Check our automated testing workflow for the proper Git hash to use to build RDycore. The linked line specifies a Docker image containing the \"blessed\" version of PETSc, which can be read as follows:</p> <pre><code>coherellc/rdycore-petsc:fc288817-int32\n</code></pre> <ul> <li><code>coherellc</code> is the name of the DockerHub organization hosting the image</li> <li><code>rdycore-petsc</code> is the the name of the Docker image</li> <li><code>fc288817</code> is the Git hash within the PETSc repository   used to build RDycore</li> <li><code>int32</code> (or <code>int64</code>) indicates whether the PETSc installation within the image   uses 32-bit or 64-bit integers for the <code>PetscInt</code> data type.</li> </ul> <p>See our PETSc Dockerfile for an example of the <code>configure</code> command we use to build PETSc in our continous integration environment.</p>"},{"location":"common/installation.html#clone-the-repository","title":"Clone the Repository","text":"<p>First, go get the source code at GitHub:</p> SSHHTTPS <pre><code>git clone git@github.com:RDycore/RDycore.git\n</code></pre> <pre><code>git clone https://github.com/RDycore/RDycore.git\n</code></pre> <p>This places an <code>RDycore</code> folder into your current path. Then we need to update the submodules.</p> <pre><code>cd RDycore\ngit submodule update --init --recursive\n</code></pre>"},{"location":"common/installation.html#configure-rdycore","title":"Configure RDycore","text":"<p>RDycore uses CMake, and can be easily configured as long as PETSc is installed and the <code>PETSC_DIR</code> and <code>PETSC_ARCH</code> environment variables are set properly. Usually all you need to do is change to your <code>RDycore</code> source directory and type</p> <pre><code>cmake -S . -B build\n</code></pre> <p>where <code>build</code> is the name of your build directory relative to the source directory. If you want to install RDycore somewhere afterward, e.g. to be able to configure E3SM to use it, you can set the prefix for the installation path using the <code>CMAKE_INSTALL_PREFIX</code> parameter:</p> <pre><code>cmake -S . -B build -DCMAKE_INSTALL_PREFIX=/path/to/install\n</code></pre>"},{"location":"common/installation.html#supported-configuration-options","title":"Supported configuration options","text":"<p>CMake allows you to specify build options with the <code>-D</code> flag, as indicated in Step 3 above. Here are the options supported by RDycore:</p> <ul> <li><code>CMAKE_INSTALL_PREFIX=/path/to/install</code>: a path to which the RDycore library   and driver are installed with <code>make install</code> (as in Step 7)</li> <li><code>CMAKE_BUILD_TYPE=Debug|Release</code>: controls whether a build has debugging   information or whether it is optimized</li> <li><code>CMAKE_VERBOSE_MAKEFILE=ON|OFF</code>: if <code>ON</code>, displays compiler and linker   output while building. Otherwise displays only the file being built.</li> <li><code>ENABLE_COVERAGE=ON|OFF</code>: if <code>ON</code>, enables code coverage instrumentation.</li> </ul> <p>Since RDycore gets most of its configuration information from PETSc, we don't need to use most other CMake options.</p>"},{"location":"common/installation.html#considerations-for-apple-hardware","title":"Considerations for Apple hardware","text":"<p>If you're on a Mac, make sure you have installed the XCode Command Line Tools. If you have, these tools should be located in <code>/Library/Developer/CommandLineTools/usr/bin/</code>, so add this directory to your <code>PATH</code>.</p>"},{"location":"common/installation.html#build-test-and-install-rdycore","title":"Build, Test, and Install RDycore","text":"<p>After you've configured RDycore, you can build it:</p> <ol> <li>Change to your build directory (e.g. <code>cd build</code>)</li> <li>Type <code>make -j</code> to build the library.</li> <li>To run tests for the library (and the included drivers), type <code>make test</code>.</li> <li>To install the model to the location (indicated by your <code>CMAKE_INSTALL_PREFIX</code>,    if you specified it), type <code>make install</code>. By default, products are installed    in the <code>include</code>, <code>lib</code>, <code>bin</code>, and <code>share</code> subdirectories of this prefix.</li> </ol>"},{"location":"common/installation.html#running-tests","title":"Running Tests","text":"<p>RDycore uses CTest, CMake's testing program, to run its tests. CTest is very fancy and allows us to run tests selectively and in various ways, but all you need to do to run all the tests for RDycore is to change to your build directory and type</p> <pre><code>make test\n</code></pre> <p>This runs every test defined in your build configuration and dumps the results to <code>Testing/Temporary/LastTest.log</code>.</p>"},{"location":"common/installation.html#measuring-code-coverage","title":"Measuring Code Coverage","text":"<p>RDycore can use gcov or lcov to analyze code coverage (the fraction of source code that is exercised by programs and tests) with the GCC or Clang compilers.</p> <p>To instrument the <code>rdycore</code> library and unit tests for code coverage analysis, pass the <code>-DENABLE_COVERAGE=ON</code> flag to CMake when configuring your build. Then, after building and running tests, type</p> <pre><code>make coverage\n</code></pre> <p>to generate a single report (<code>coverage.info</code>) containing all coverage information. See the documentation for <code>gcov</code> and <code>lcov</code> (linked above) for details on how to interpret th\u0456s information.</p>"},{"location":"common/installation.html#checking-for-memory-errors-and-leaks-with-valgrind","title":"Checking for memory errors and leaks with Valgrind","text":"<p>If you're using a Linux system and have Valgrind installed, you can run our tests using Valgrind's <code>memcheck</code> tool with</p> <pre><code>make memcheck\n</code></pre>"},{"location":"common/installation.html#making-code-changes-and-rebuilding","title":"Making code changes and rebuilding","text":"<p>Notice that you must build RDycore in a  build tree, separate from its source trees. This is standard practice in CMake-based build systems, and it allows you to build several different configurations without leaving generated and compiled files all over your source directory. However, you might have to change the way you work in order to be productive in this kind of environment.</p> <p>When you make a code change, make sure you build from the build directory that you created in step 1 above:</p> <pre><code>cd /path/to/RDycore/build\nmake -j\n</code></pre> <p>You can also run tests from this build directory with <code>make test</code>.</p> <p>This is very different from how some people like to work. One method of making this easier is to use an editor in a dedicated window, and have another window open with a terminal, sitting in your <code>build</code> directory. If you're using a fancy modern editor, it might have a CMake-based workflow that handles all of this for you.</p> <p>The build directory has a structure that mirrors the source directory, and you can type <code>make</code> in any one of its subdirectories to do partial builds. In practice, though, it's safest to always build from the top of the build tree.</p>"},{"location":"common/installation.html#preinstalled-petsc-for-rdycore-on-certain-doe-machines","title":"Preinstalled PETSc for RDycore on certain DOE machines","text":"<p>The RDycore team supports installation of the model at following DOE machines:</p> <ol> <li>Perlmutter at NERSC</li> <li>Frontier at OLCF</li> </ol> <p>First, run the following shell script to set PETSc-related environmental variables and load appropriate modules.</p> <pre><code>`source config/set_petsc_settings.sh --mach &lt;machine_name&gt; --config &lt;configuration&gt;`,\n</code></pre> <p>Multiple configurations of PETSc have been pre-installed on these supported machines under RDycore's project directories. Information about the available PETSc configurations can be obtained via <code>./config/set_petsc_settings.sh</code>.</p> <p>The Perlmutter system has two types of compute nodes: CPU-only and CPU-GPU nodes, and RDycore needs to be build separately for each type of compute node. The CPU-only nodes have 128 cores (2 x 64-core AMD EPYC CPUs), while the CPU-GPU nodes have 1 x 64-core AMD EPYC CPU and 4 x NVIDIA A100. RDycore uses PETSc's and libCEED's support of CUDA to run on Perlmutter GPUs.</p> <p>Frontier has a single type of compute node that has 64-core AMD and 4x AMD MI250X GPUs. Each GPU has 2 Graphics Compute Dies (GCDs) for a total of 8 GCDs per node. Of the 64-cores, only 56 are allocatable cores instead of 64 cores. RDycore uses PETSc's and libCEED's support of HIP to run on AMD GPUs.</p>"},{"location":"common/installation.html#example-building-and-running-rdycore-on-perlmutter-cpu-nodes","title":"Example: Building and running RDycore on Perlmutter CPU nodes","text":"<pre><code>cd /path/to/RDycore\n\n# Set PETSc environment variables for Perlmutter CPU nodes\nsource config/set_petsc_settings.sh --mach pm-cpu --config 1\n\n# Build RDycore\ncmake -S . -B build-$PETSC_ARCH -DCMAKE_INSTALL_PREFIX=$PWD/build-$PETSC_ARCH\ncd build-$PETSC_ARCH\nmake -j4 install\n\n# Use an interactive job queue\nsalloc --nodes 1 --qos interactive --time 00:30:00 --constraint cpu \\\n--account=&lt;project-id&gt;\n\n# Change to the directory containing tests\ncd driver/tests/swe_roe\n\n# Run on 4 MPI tasks on CPUs\nsrun -N 1 -n 4 ../../rdycore ex2b_ic_file.yaml -ceed /cpu/self -log_view\n</code></pre>"},{"location":"common/installation.html#example-building-and-running-rdycore-on-perlmutter-gpu-nodes","title":"Example: Building and running RDycore on Perlmutter GPU nodes","text":"<pre><code>cd /path/to/RDycore\n\n# Set PETSc environment variables for Perlmutter GPU nodes\nsource config/set_petsc_settings.sh --mach pm-gpu --config 1\n\n# Build RDycore\ncmake -S . -B build-$PETSC_ARCH -DCMAKE_INSTALL_PREFIX=$PWD/build-$PETSC_ARCH\ncd build-$PETSC_ARCH\nmake -j4 install\n\n# Use an interactive job queue\nsalloc --nodes 1 --qos interactive --time 00:30:00 --constraint gpu \\\n--gpus 4 --account=&lt;project-id&gt;_g\n\n# Change to the directory containing tests\ncd driver/tests/swe_roe\n\n# Run on 4 GPUs using CUDA\nsrun -N 1 -n 4 -c 32 ../../rdycore ex2b_ic_file.yaml \\\n-ceed /gpu/cuda -dm_vec_type cuda -log_view -log_view_gpu_time\n</code></pre>"},{"location":"common/installation.html#example-building-and-running-rdycore-on-frontier","title":"Example: Building and running RDycore on Frontier","text":"<pre><code>cd /path/to/RDycore\n\n# Set PETSc environment variables for Frontier\nsource config/set_petsc_settings.sh --mach frontier --config 1\n\n# Build RDycore\ncmake -S . -B build-$PETSC_ARCH -DCMAKE_INSTALL_PREFIX=$PWD/build-$PETSC_ARCH\ncd build-$PETSC_ARCH\nmake -j4 install\n\n# Use an interactive job queue\nsalloc -N 1 -A &lt;project-id&gt; -t 0:30:00 -p batch\n\n# Change to the directory containing tests\ncd driver/tests/swe_roe\n\n# Run on CPUs\nsrun -N 1 -n8 -c1 ../../rdycore ex2b_ic_file.yaml -ceed /cpu/self -log_view\n\n# Run on 8 GPUs using HIP\nsrun -N 1 -n8 -c1 ../../rdycore ex2b_ic_file.yaml \\\n-ceed /gpu/hip -dm_vec_type hip -log_view -log_view_gpu_time\n</code></pre>"},{"location":"common/mms.html","title":"The Method of Manufactured Solutions (MMS) Verification Driver","text":""},{"location":"common/mms.html#input","title":"Input","text":"<p>The MMS driver accepts input in YAML form, like the main RDycore driver. However, the MMS driver's input has a \u0455lightly different form. Like the main driver input, it's organized into several sections. Many of these sections are identical to those in the main driver's input:</p> <ul> <li>Model equations and discretizations<ul> <li>physics</li> <li>numerics</li> <li>grid</li> <li>regions</li> <li>boundaries</li> <li>time</li> </ul> </li> <li>Simulation diagnostics, output, and restarts<ul> <li>logging</li> <li>output</li> </ul> </li> </ul> <p>However, the other sections, which define material properties, initial/boundary conditions, and sources, are not present in the MMS input. This is because the method manufactured solutions requires analytic forms for these terms to produce a convergent manufactured solution. So these sections are replaced by a single <code>mms</code> section that defines these analytic forms.</p>"},{"location":"common/mms.html#mms-section","title":"<code>mms</code> section","text":"<pre><code>mms:\n  constants: # any single capital letter can be used\n    H: 0.005  # water height scale factor\n    T: 20.0   # time scale\n    U: 0.025  # x-velocity scale factor\n    V: 0.025  # y-velocity scale factor\n    N: 0.01   # manning coefficient scale factor\n    Z: 0.0025 # elevation scale factor\n\n    K: 0.6283185307179586 # wave number in x and y (pi/5)\n  swe: # functions of x, y, t (non-normalized units)\n    # water height\n    h:    H * (1 + sin(K*x)*sin(K*y)) * exp(t/T)\n    dhdx: H * K * sin(K*y) * cos(K*x) * exp(t/T)\n    dhdy: H * K * sin(K*x) * cos(K*y) * exp(t/T)\n    dhdt: H / T * (1 + sin(K*x)*sin(K*y)) * exp(t/T)\n\n    # x velocity\n    u:     U * cos(K*x) * sin(K*y) * exp(t/T)\n    dudx: -U * K * sin(K*x) * sin(K*y) * exp(t/T)\n    dudy:  U * K * cos(K*x) * cos(K*y) * exp(t/T)\n    dudt:  U / T * cos(K*x) * sin(K*y) * exp(t/T)\n\n    # y velocity\n    v:     V * sin(K*x) * cos(K*y) * exp(t/T)\n    dvdx:  K * V * cos(K*x) * cos(K*y) * exp(t/T)\n    dvdy: -K * V * sin(K*x) * sin(K*y) * exp(t/T)\n    dvdt:  V / T * sin(K*x) * cos(K*y) * exp(t/T)\n\n    # elevation as z(x, y)\n    z:     Z * sin(K*x) * sin(K*y)\n    dzdx:  Z * K * cos(K*x) * sin(K*y)\n    dzdy:  Z * K * sin(K*x) * cos(K*y)\n\n    # Manning coefficient n(x,y)\n    n:     N * (1 + sin(K*x) * sin(K*y))\n\n  # Convergence study parameters (optional)\n  convergence:\n    num_refinements: 3\n    base_refinement: 1\n    expected_rates:\n      h:\n        L1: 1\n        L2: 1\n        Linf: 0.48\n      hu:\n        L1: 0.73\n        L2: 0.78\n        Linf: 0.62\n      hv:\n        L1: 0.73\n        L2: 0.78\n        Linf: 0.62\n</code></pre> <p>The <code>mms</code> section defines the forms of the manufactured solutions for the model equations corresponding to parameters set in the <code>physics</code> section.</p> <p>The <code>constants</code> subsection define\u0455 a set of named constants that can be used in the analytic forms for the manufactured solutions. Any single capital roman letter (<code>A</code> through <code>Z</code>) can be used as a constant. In the above example, the solutions reference the constants <code>H</code>, <code>T</code>, <code>U</code>, <code>V</code>, <code>N</code>, <code>Z</code>, and <code>K</code>, which are defined as shown.</p> <p>The <code>swe</code> subsection defines a set of manufactured solutions to the 2D shallow water equations (SWE) in terms of a water height <code>h</code> with a flow velocity <code>(u, v)</code>. Each of the components <code>h, u, v</code> are represented by a function of the coordinates <code>x</code> and <code>y</code> and the time <code>t</code>. Other model parameters (<code>z</code>, the elevation function, and <code>n</code>, the Manning coefficient) are functions of <code>x</code> and <code>y</code> only.</p> <p>These analytic forms are parsed and compiled at runtime so they can be evaluated as needed by the model. This means you can define a new manufactured solution in every MMS driver input file, without developing code and rebuilding RDycore.</p>"},{"location":"common/mms.html#convergence-studies","title":"Convergence studies","text":"<p>The optional <code>convergence</code> subsection contains the following parameters for performing convergence studies that determine whether the MMS problem has been solved successfully for each solution component:</p> <ul> <li><code>num_refinements</code>: the number of times the domain (and timestep) are refined   uniformly from the base resolution to test the rate of convergence of the   solution error. This parameter is required.</li> <li><code>base_refinement</code>: this optional parameter specifies the number of times the   mesh should be refined to establish the coarsest resolution to be used in the   convergence study. For example, a <code>base_refinement</code> of 2 indicates that a   mesh loaded from a file should be refined twice before performing a   convergence study.</li> <li><code>expected_rates</code>: a sub-subsection with <code>L1</code>, <code>L2</code>, and <code>Linf</code>   entries for each relevant solution component name giving the expected rates of   convergence for the appropriate error norms. Each of the component names and   expected rates are optional, so you can specify only those you want to use   as pass/fail criteria.</li> </ul> <p>NOTE: When the MMS driver performs a convergence study, it writes no output. If you need to write a mesh or solution data, you can always use an input file without the <code>convergence</code> section to compute error norms for a single spatial resolution, writing output as needed.</p>"},{"location":"developer/index.html","title":"RDycore Developer Guide - Overview","text":"<p>This document contains information for anyone interested in helping to develop and/or maintain RDycore.</p> <p>RDycore comprise\u0455 several related components:</p> <ul> <li>a C library that implements the actual river dynamical core model using   PETSc, which provides performance portable   numerical solvers, data structures like unstructured grids and vectors,   and basic system-level utilities</li> <li>a Fortran library consisting of a thin wrapper around the C library, with   exactly the same functionality</li> <li>standalone C and Fortran driver programs that demonstrate the capabilities of   the RDycore library using RDycore's YAML input format</li> <li>various other programs and tools, including C and Fortran drivers that   can evaluate rates of convergence in the solution error for RDycore when   applied to specific analytical problems</li> </ul> <p>Most of these components are interesting only to RDycore developers. For those who wish to incorporate RDycore within a larger framework like E3SM, the C and Fortran RDycore libraries (<code>librdycore.a</code> and <code>librdycore_f90.a</code>, when built) and their corresponding header/module files (<code>rdycore.h</code> and <code>rdycore.mod</code>, respectively) are all that is needed.</p>"},{"location":"developer/index.html#the-rdycore-library","title":"The RDycore library","text":""},{"location":"developer/index.html#contents","title":"Contents","text":"<ul> <li>Building and Installing RDycore</li> <li>Development Process</li> <li>Code Structure and Organization</li> <li>Developer Tools</li> <li>Integrating RDycore with E3SM</li> <li>Mesh Description</li> </ul>"},{"location":"developer/ceed.html","title":"RDycore SWE physics with CEED","text":"<p>Here we describe the RDycore's implemetation of 2D shallow water equation (SWE) that uses libCEED. The combination of PETSc and libCEED provides RDDycore algorithimic and hardware protability.</p> <ul> <li>RDycore uses PETSc's <code>TS</code> solvers that provide support for multiple time-integrators such as forward euler, RK4, etc., which can be selected at run time (e.g. <code>--ts_type euler</code>, <code>--ts_type rk4</code>, etc). </li> <li>Using libCEED allows RDycore to compute the RHSFunction for PETSc's explicit <code>TS</code> methods on CPU or GPU, which can also be selected at runtime via<ul> <li>For CPUs: <code>-ceed /cpu/self</code></li> <li>For NVIDIA GPUs: <code>-ceed /gpu/cuda -dm_vec_type cuda</code></li> <li>For AMD GPUs: <code>-ceed /gpu/hip -dm_vec_type hip</code></li> </ul> </li> </ul>"},{"location":"developer/ceed.html#example-mesh","title":"Example Mesh","text":"<p>Let's consider an example 3x2 mesh that consists of</p> <ul> <li>6 cells: <code>c00</code> to <code>c05</code></li> <li>17 edges: <code>e00</code> to <code>e16</code><ul> <li>Internal edges: <code>e04</code>, <code>e05</code>, <code>e07</code>, <code>e08</code>, <code>e09</code>, <code>e11</code>, and <code>e12</code></li> <li>Boundary edges: <code>e00</code>, <code>e01</code>, <code>e02</code>, <code>e03</code>, <code>e06</code>, <code>e10</code>, <code>e13</code>, <code>e14</code>, <code>e15</code>, and <code>e16</code></li> </ul> </li> <li>12 vertices: <code>v00</code> to <code>v11</code></li> </ul> <pre><code>v08---e14---v09---e15---v10---e16---v11\n |           |           |           |\n |           |           |           |\ne10   c03   e11   c04   e12   c05   e13\n |           |           |           |\n |           |           |           |\nv04---e07---v05---e08---v06---e09---v07\n |           |           |           |\n |           |           |           |\ne03   c00   e04   c01   e05   c02   e06\n |           |           |           |\n |           |           |           |\nv00---e00---v01---e01---v02---e02---v03\n</code></pre> <p>A PETSc Vec (<code>X</code>) with stride <code>3</code>, with components corresponding to the following prognostic variables: The block size of <code>X</code> is <code>3</code> corresponding to the following prognostic variables:</p> <ul> <li>Height (<code>h</code>),</li> <li>Momentum in x-dir (<code>hu</code>), and</li> <li>Momentum in y-dir (<code>hv</code>). The size of <code>X</code> will <code>6 * 3</code> where <code>6</code> corresponds to number of cells in the mesh. The layout of <code>X</code> will be as follows:</li> </ul> <pre><code>X = [[h0 hu0 hv0] [h1 hu1 hv1] ... [h5 hu5 hv5]]\n</code></pre>"},{"location":"developer/ceed.html#swe-physics-with-libceed","title":"SWE physics with libCEED","text":"<p>The libCEED version of RDycore's explicit time-integrator of the SWE solver has two <code>CeedOperator</code>s:</p> <ol> <li> <p><code>rdy-&gt;ceed_rhs.op_edges</code> : This operator computes fluxes across edges, and includes \"sub-operators\" that handle internal edges and boundary edges separately.</p> </li> <li> <p><code>rdy-&gt;ceed_rhs.src</code>: This operator computes source terms such as water added by rainfall and terms associated with bed slope and friction.</p> </li> </ol>"},{"location":"developer/ceed.html#ceedoperator-for-internal-edges","title":"<code>CeedOperator</code> for Internal Edges","text":"<p>RDycore uses first-order finite volume discretization to compute the flux across the edges, which requires values on the left and the right of the edge.</p> Internal Edge Left Cell Right cell e04 c00 c01 e05 c01 c02 e07 c00 c03 e08 c01 c04 e09 c02 c05 e11 c03 c04 e12 c04 c05 <p>The steps involved in creating the <code>CeedOperator</code> associated with the internal edges are as follows:</p> <ul> <li>First, create a <code>CeedQFunction</code>, <code>qf</code>, and add input and output fields. The input fields include geometric attributes associated with the edges and the prognostic variables to the left left and right of the edges. The output fields include contribution of fluxes to the cells left and right of the edge and a diagnostic variable that saves fluxes through the edge. The pointer to the user-defined function is specified at the time of creation.</li> </ul> Field name Size In/Out Notes <code>geom</code> <code>4</code> In Geometric attrbutes [sn, cn, L_edge/Area_left, L_edge/right] <code>q_left</code> <code>3</code> In State left of the edge [h_left, hu_left, hv_left] <code>q_right</code> <code>3</code> In State right of the edge [h_right, hu_right, hv_right] <code>cell_left</code> <code>3</code> Out Flux contribution to the left cell [f_h f_hu f_hv] * L_edge/Area_left <code>cell_right</code> <code>3</code> Out Flux contribution to the right cell [f_h f_hu f_hv] * L_edge/Area_right <code>flux</code> <code>3</code> Out Flux through the edge [f_h f_hu f_hv] <code>courant_number</code> <code>2</code> Out Courant number for the left and right cell <ul> <li>Second, create <code>CeedElemRestriction</code> for all the input and output fields of previously created <code>CeedQFunction</code>. A <code>CeedElemRistriction</code> tells libCEED the indices of a <code>CeedVector</code> from/to which the values are to extracted/written for an input/output field. The <code>CeedElemRestriction</code> for the fields and the example mesh is given below.</li> </ul> Variable name Size of offset Size of CeedVector Created via Notes <code>restrict_geom</code> <code>nOwnedInEdges</code> <code>4 * nOwnedInEdges</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  4,  8, 12, 16, 20, 24] <code>q_restrict_l</code> <code>nOwnedInEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 0,  3,  0,  3,  6,  9, 12] <code>q_restrict_r</code> <code>nOwnedInEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 3,  6,  9, 12, 15, 12, 15] <code>c_restrict_l</code> <code>nOwnedInEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 0,  3,  0,  3,  6,  9, 12] <code>c_restrict_r</code> <code>nOwnedInEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 3,  6,  9, 12, 15, 12, 15] <code>restrict_flux</code> <code>nOwnedInEdges</code> <code>3 * nOwnedInEdges</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  3,  6,  9, 12, 15, 18] <code>restrict_cnum</code> <code>nOwnedInEdges</code> <code>2 * nOwnedInEdges</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  2,  4,  6,  8, 10, 12] <p>where <code>nOwnedInEdges</code> is the number of owned internal edges and <code>nCells</code> is the total number of cells ( = owned + ghost).</p> <ul> <li>Third,  create the <code>CeedOperator</code> using the previously created <code>CeedQFunction</code> and all <code>CeedElementRestriction</code>. The multiple fields are added via <code>CeedOperatorSetField</code>.</li> </ul> Field name CeedElemRestriction CeedVector Notes <code>geom</code> <code>restrict_geom</code> <code>geom</code> <code>geom</code> has values <code>geom[:][0:3] = [sn cn L/A_l L/A_r]</code> <code>q_left</code> <code>q_restrict_l</code> <code>CEED_VECTOR_ACTIVE</code> <code>q_right</code> <code>q_restrict_r</code> <code>CEED_VECTOR_ACTIVE</code> <code>cell_left</code> <code>c_restrict_l</code> <code>CEED_VECTOR_ACTIVE</code> <code>cell_right</code> <code>c_restrict_r</code> <code>CEED_VECTOR_ACTIVE</code> <code>flux</code> <code>restrict_flux</code> <code>flux</code> <code>flux</code> is initalized to <code>0.0</code> <code>courant_number</code> <code>restrict_cnum</code> <code>cnum</code> <code>cnum</code> is initalized to <code>0.0</code>"},{"location":"developer/ceed.html#ceedoperator-for-boundary-edges","title":"<code>CeedOperator</code> for Boundary Edges","text":"<p>The values right of the edge are provided if a Dirichlet boundary condition is applied on that edge For a reflective boundary condition, the value on the left of the edge is used as the value on right of the edge. Based on the mesh shown above, the boundary edges are listed in the table below.</p> Boundary Edge Left Cell (Optional) Dirichlet Right cell e00 c00 d00 e01 c01 d01 e02 c02 d02 e03 c00 d03 e06 c02 d04 e10 c03 d05 e13 c05 d06 e14 c03 d07 e15 c04 d08 e16 c05 d09 <p>The fields for the boundary condition <code>CeedQFunction</code> are listed below. It should be noted that the <code>geom</code> field for a boundary edge has one geometric attribute fewer than the <code>geom</code> field for an intenral edge because the value <code>L_edge/A_right</code> is not needed for a boundary edge. Similarly, the <code>cell_right</code> field is omitted for a boundary edge.</p> Field name Size In/Out Notes <code>geom</code> <code>3</code> In Geometric attrbutes [sn, cn, L_edge/Area_left] <code>q_left</code> <code>3</code> In State left of the edge [h_left, hu_left, hv_left] <code>q_dirichlet</code> <code>3</code> In (Optional) Dirichlet boundary state right of the edge [h_bc, hu_bc, hv_bc] <code>cell_left</code> <code>3</code> Out Flux contribution to the left cell [f_h f_hu f_hv] * L_edge/Area_left <code>flux</code> <code>3</code> Out Flux through the edge [f_h f_hu f_hv] <code>courant_number</code> <code>1</code> Out Courant number for the left cell <p>The <code>CeedElemRestriction</code> for the boundary fields are listed below.</p> Variable name Size of offset Size of CeedVector Created via Notes <code>restrict_geom</code> <code>nOwnedBndEdges</code> <code>3 * nOwnedBndEdges</code> <code>CeedElemRestrictionCreateStrided</code> [ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27, 30] <code>q_restrict_l</code> <code>nOwnedBndEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> [ 0,  3,  6,  0,  6,  9,  9, 15,  9, 12, 15] <code>restrict_dirichlet</code> <code>nOwnedBndEdges</code> <code>3 * nOwnedBndEdges</code> <code>CeedElemRestrictionCreate</code> [ 3,  6,  9, 12, 15, 12, 15] <code>c_restrict_l</code> <code>nOwnedBndEdges</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> [ 0,  3,  0,  3,  6,  9, 12] <code>restrict_flux</code> <code>nOwnedBndEdges</code> <code>3 * nOwnedBndEdges</code> <code>CeedElemRestrictionCreateStrided</code> [ 0,  3,  6,  9, 12, 15, 18] <code>restrict_cnum</code> <code>nOwnedBndEdges</code> <code>1 * nOwnedBndEdges</code> <code>CeedElemRestrictionCreateStrided</code> [ 0,  1,  2,  3,  4,  5,  6] <p>where <code>nOwnedBndEdges</code> is the number of owned boundary edges and <code>nCells</code> is the total number of cells ( = owned + ghost). The fields, <code>CeedElemRestriction</code>, and <code>CeedVector</code> that are used to create the boundary <code>CeedOperator</code> are summarized below.</p> Field name CeedElemRestriction CeedVector Notes <code>geom</code> <code>restrict_geom</code> <code>geom</code> <code>geom</code> has values <code>geom[:][0:2] = [sn cn L/A_l]</code> <code>q_left</code> <code>q_restrict_l</code> <code>CEED_VECTOR_ACTIVE</code> <code>q_dirichlet</code> <code>restrict_dirichlet</code> <code>CEED_VECTOR_ACTIVE</code> <code>cell_left</code> <code>c_restrict_l</code> <code>CEED_VECTOR_ACTIVE</code> <code>flux</code> <code>restrict_flux</code> <code>flux</code> <code>flux</code> is initalized to <code>0.0</code> <code>courant_number</code> <code>restrict_cnum</code> <code>cnum</code> <code>cnum</code> is initalized to <code>0.0</code>"},{"location":"developer/ceed.html#ceedoperator-for-sourcesink","title":"<code>CeedOperator</code> for Source/Sink","text":"<p>The fields for the source/sink <code>CeedQFunction</code> are listed below.</p> Field name Size In/Out Notes <code>geom</code> <code>2</code> In Geometric attrbutes [dz/dx, dz/y] <code>swe_src</code> <code>3</code> In Source/sink value for the three prognostic variables <code>mannings_n</code> <code>1</code> In Mannings roughness coefficient <code>riemannf</code> <code>3</code> In Sum of fluxes in/out of a cell <code>q</code> <code>3</code> In The prognostic variables [h, hu, hv] <code>cell</code> <code>3</code> Out The RHS value of the ODE for the TS solver <p>The <code>CeedElemRestriction</code> for the source/sink fields are listed below.</p> Variable name Size of offset Size of CeedVector Created via Notes <code>restrict_geom</code> <code>nOwnedCells</code> <code>2 * nOwnedCells</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  3,  6,  9, 12, 15] <code>restrict_swe</code> <code>nOwnedCells</code> <code>3 * nOwnedCells</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  3,  6,  9, 12, 15] <code>restrict_mannings_n</code> <code>nOwnedCells</code> <code>1 * nOwnedCells</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  3,  6,  9, 12, 15] <code>restrict_riemannf</code> <code>nOwnedCells</code> <code>3 * nOwnedCells</code> <code>CeedElemRestrictionCreateStrided</code> offset = [ 0,  3,  6,  9, 12, 15] <code>restrict_q</code> <code>nOwnedCells</code> <code>3 * nCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 0,  3,  6,  9, 12, 15] <code>restrict_c</code> <code>nOwnedCells</code> <code>3 * nOwnedCells</code> <code>CeedElemRestrictionCreate</code> offset = [ 0,  3,  6,  9, 12, 15] <p>where <code>nOwnedCells</code> is the number of owned cells and <code>nCells</code> is the total (= owned + ghost) cells. The fields, <code>CeedElemRestriction</code>, and <code>CeedVector</code> that are used to create the source/sink <code>CeedOperator</code> are summarized below.</p> Field name CeedElemRestriction CeedVector Notes <code>geom</code> <code>restrict_geom</code> <code>geom</code> <code>geom</code> has values <code>geom[:][0:2] = [dz/dx dz/dy]</code> <code>swe_src</code> <code>restrict_swe</code> <code>swe_src</code> <code>swe_src</code> has values for the source/sink term <code>mannings_n</code> <code>restrict_mannings_n</code> <code>mannings_n</code> <code>mannings_n</code> has values corresponding to Mannings coefficient <code>riemannf</code> <code>restrict_riemannf</code> <code>riemannf</code> <code>riemannf</code> has the sum of Riemann fluxes in a cell through internal and boundary edges <code>q</code> <code>restrict_q</code> <code>CEED_VECTOR_ACTIVE</code> <code>cell</code> <code>restrict_c</code> <code>CEED_VECTOR_ACTIVE</code>"},{"location":"developer/ceed.html#schematic-representation-of-rhsfunction-with-libceed","title":"Schematic Representation of RHSFunction with libCEED","text":""},{"location":"developer/development.html","title":"RDycore Development Process","text":"<p>Here we discuss the practices and tools used to develop RDycore. The RDycore team is a small interdisciplinary team, and our development process is tailored to its particular needs. These needs necessarily evolve over the lifecycle of the project, so this process is likely to change from time to time.</p> <p>There is no single process that works best in every situation. This is as true for software development as it is for the approximations used in basic science and mathematical modeling, and for rules of engagement in all human activites. The working styles, expertise, and needs of individual team members determine the shape of the process that makes them most productive.</p>"},{"location":"developer/development.html#git-code-repository-and-workflow","title":"Git Code Repository and Workflow","text":"<p>Like all E3SM \"ecosystem\" projects, RDycore stores its source code in a GitHub repository. The RDycore GitHub Organization contains this and other repositories related to the project.</p> <p>We develop RDycore using the Git feature branch workflow, which is among the more popular Git-based development methodologies. In this workflow:</p> <ul> <li>the main branch contains the   latest working code that has passed all tests and quality controls</li> <li>all work on any new feature or bugfix is performed by one or more team members   in a \"feature branch\" created from this main branch</li> <li>when work in a feature branch is finished and ready for incorporation into   the main branch, one of the participating team members creates a pull request   which, upon successful review, is merged to the <code>main</code> branch<ul> <li>each pull request to be merged with the <code>main</code> branch triggers a set of   automated tests that build RDycore, run its test suite, and perform some   basic quality checks (code formatting, test coverage, etc)</li> <li>one or more members of the RDycore team must be assigned to review the   code changes in the feature branch before it can be merged</li> <li>a code reviewer can ask questions about, request changes to, or approve   the code in the pull request</li> <li>at least one approval from a reviewer is required to merge the pull   request (which may or may not require conflicts to be resolved between   the feature branch and the <code>main</code> branch)</li> </ul> </li> </ul>"},{"location":"developer/development.html#keep-it-short-and-simple","title":"Keep it short and simple!","text":"<p>Because long-lived feature branches are correlated with increasing numbers of merge conflicts and other inconsistent states within the repository, it is recommended that feature branches are short-lived, tightly-scoped, and merged in a timely fashion. Such branches are also much easier to review for errors and inconsistencies.</p> <p>Occasionally, it may be necessary to create a long-lived feature branch. Such a branch must be managed actively and carefully to accommodate the complexity it introduces to the development process. Reviewing a long-lived feature branch is a difficult and time-intensive process, so make sure you know what you're getting into if you think you need one.</p>"},{"location":"developer/development.html#third-party-libraries","title":"Third-Party Libraries","text":"<p>RDycore relies on PETSc for much of its functionality, including most of its third-party libraries such as NetCDF, HDF5, and Exodus. You can find details for installing the right version of PETSc with all the necessary third-party libraries in the installation guide.</p> <p>Additionally, RDycore uses a few other libraries not available from PETSc:</p> <ul> <li>libcyaml - A schema-based YAML parser we   use to parse RDycore's flexible and expressive input format</li> <li>libyaml - the original C YAML parser, which   is used by <code>libcyaml</code> above</li> <li>cmocka - a C unit testing framework that we use for   testing some low-level features</li> </ul> <p>These libraries are imported into the RDycore repo as Git submodules. Git submodules are like \"repos within a repo\", which is a half-baked concept that makes them tricky to use at times, but you won't spend much time thinking about them unless one of the above libraries is updated. Usually, all you have to do is type</p> <pre><code>git submodule update --init --recursive\n</code></pre> <p>from the top level of the RDycore source tree, which ensures that the submodules in your local Git workspace are consistent with the branch you're working in.</p>"},{"location":"developer/development.html#cmake-build-system","title":"CMake Build System","text":"<p>Like all E3SM-related projects, RDycore uses CMake as a configuration/build system. CMake is the most common build system for C and C++ projects. It can be very complicated if all of its features are used indiscriminately, and it's difficult even to understand all of its features. The RDycore project has tried to confine its CMake usage to the bare essentials, in the interest of creating a simple and reproducible build and development environment.</p> <p>Here we describe the basic structure of our CMake setup. For instructions on how to build RDycore using this build system, refer to the installation guide.</p> <p>The build system is composed of a set of <code>CMakeLists.txt</code> files that define various parts of RDycore:</p> <ul> <li>The <code>CMakeLists.txt</code> file in the top-level source directory defines the   project and configures PETSc and compilers and refers to other directories   containing their own <code>CMakeLists.txt</code> files.</li> <li>The <code>external</code> directory has its own <code>CMakeLists.txt</code> file that builds the   third-party libraries that aren't available as part of PETSc's distribution.</li> <li>The <code>src</code> directory contains all the source files, and the <code>CMakeLists.txt</code>   therein builds the RDycore C library. A <code>tests</code> subdirectory has a <code>CMakeLists.txt</code>   file that defines unit tests for the library, and the <code>f90-mod</code> subdirectory   has one that builds the Fortran library.</li> <li>The <code>driver</code> directory contains source files for the C and Fortran standalone   driver programs and other developer tools, and the <code>CMakeLists.txt</code> file   defines their build configurations. A <code>tests</code> subdirectory defines several   tests for these drivers and tools.</li> <li>Various other directories have <code>CMakeLists.txt</code> files that perform tasks   related to their content.</li> </ul>"},{"location":"developer/development.html#cmake-targets-and-dependencies","title":"CMake targets and dependencies","text":"<p>Like Make, CMake defines \"targets\" to build and expresses dependenceis between these targets to determine the order in which everything is built. For example, the RDycore standalone driver (represented by the <code>rdycore_exe</code> target defined in driver/CMakeLists.txt) depends upon the RDycore C library (the <code>rdycore</code> target in src/CMakeLists.txt), so the <code>rydcore</code> target must be built before the <code>rdycore_exe</code> target.</p> <p>If you're curious about how CMake works in detail, Kitware has a tutorial on their CMake website.</p>"},{"location":"developer/development.html#modern-cmake","title":"\"Modern CMake\"","text":"<p>You might hear a CMake enthusiast refer to \"Modern CMake\". This refers to the practice of setting build properties on specific targets (with commands like target_include_directories and target_link_libraries) instead of setting these properties globally (with include_directories and link_libraries).</p> <p>Using target-specific properties makes it easier to find issues with the build system. We adhere as much as possible to this practice in the development of RDycore.</p>"},{"location":"developer/development.html#ctest-automated-testing","title":"CTest Automated Testing","text":"<p>The <code>CMakeLists.txt</code> files within the test-related directories (src/tests and driver/tests define tests that are run when you type <code>make test</code>. These tests use CTest, which is an automated testing system built into CMake. The link in the previous sentence is a good resource for learning about this testing system, but you can also just run <code>make test</code> after you've successfully built RDycore to see it in action. The results of this command (testing logs, lists of failed tests, etc) can be found in the <code>Testing/Temporary</code> folder within your build directory.</p>"},{"location":"developer/development.html#github-continuous-integration-environment","title":"GitHub Continuous Integration Environment","text":"<p>Previously, we mentioned that any pull request for a feature branch to be merged to the <code>main</code> branch triggers an automated set of tests and quality checks. These tests and checks, which we refer to as RDycore's \"continuous integration (CI) environment\", are implemented using GitHub Actions.</p> <p>\"Github Actions\" are sets of logic that does work on things in repositories. These Actions can be assembled into \"GitHub Actions workflows\" that perform tasks such as building RDycore or running unit tests. GitHub Actions workflows are triggered by events in a GitHub repository such as pull requests, merges, the creation of issues, etc. Each workflow can pass or fail, making it convenient to use them as criteria for accepting new code contributions.</p> <p>Each GitHub Actions workflow is defined by a YAML file placed in the .github/workflows directory. The following workflows are defined for RDycore and are triggered by a pull request to the <code>main</code> branch:</p> <ul> <li><code>auto_test</code>: builds RDycore in a container in which PETSc is installed and   runs all of its unit tests, generating a code coverage reports. This workflow   fails if any of these operations cannot be completed successfully.</li> <li><code>clang-format-check</code>: checks C source code formatting on selected files,   failing if the code has not been formatted correctly. For information on   code formatting, see our style guide.</li> <li><code>gh-pages</code>: publishes updated documentation generated by mkdocs   from Markdown files in the <code>docs</code> directory. The documentation is published to   RDycore's GitHub Page, and a preview is   generated on the pull request page for inspection prior to a merge.</li> </ul> <p>For details on the syntax of the YAML files used to define these workflows, see the GitHub Actions documentation.</p>"},{"location":"developer/e3sm.html","title":"Integrating RDycore with E3SM","text":""},{"location":"developer/mesh.html","title":"Mesh","text":"<p>Here we describe the two mesh formats that are used in RDycore. The two mesh formats that we use are:</p> <ol> <li>Exodus II</li> <li>PETSc's DMPlex-specific, HDF5-based mesh format (version 3.0.0)</li> </ol> <p>RDycore has been tested for meshes that include triangular, quadrilateral, or both triangular and quadrilateral cells. Each cell consists of edges (3 for triangles and 4 for quadrilaterals) with vertices at the edges' endpoints. The cell vertices have three-dimensional coordinates that incorporate topographic information.</p>"},{"location":"developer/mesh.html#exodus-ii-mesh-format","title":"Exodus II Mesh Format","text":"<p>The Exodus II mesh format (<code>.exo</code>) uses 1-based indices. Exodus files are  written in the netCDF file format.</p>"},{"location":"developer/mesh.html#triangular-elements","title":"Triangular elements","text":"<pre><code>     Triangular\n        cell\n         v3\n         / \\\n        /   \\\n      e5     e4\n     /   c1   \\\n    /          \\\n  v1 --- e3 --- v2\n</code></pre> <ul> <li>The triangular cell <code>c1</code> consists of the three vertices <code>v1</code>, <code>v2</code>, and <code>v3</code></li> <li>The elem_type of <code>c1</code> is <code>TRI3</code></li> <li>It has five edges sidesets. The first two edge sidesets form a plane and the remaining   three edge sidesets are lines as follows:</li> <li><code>e1</code>: an oriented plane formed by <code>v1</code>, <code>v2</code>, <code>v3</code> (not shown above)</li> <li><code>e2</code>: an oriented plane formed by <code>v1</code>, <code>v3</code>, <code>v2</code> (not shown above)</li> <li><code>e3</code>: a directed line from <code>v1</code> to <code>v2</code></li> <li><code>e4</code>: a directed line from <code>v2</code> to <code>v3</code></li> <li><code>e5</code>: a directed line from <code>v3</code> to <code>v1</code></li> </ul>"},{"location":"developer/mesh.html#quadrilateral-elements","title":"Quadrilateral elements","text":"<pre><code>    Quadrilateral\n        cell\n  v4 --- e5 --- v3\n  |             |\n  |             | \n  e6     c1     e4\n  |             | \n  |             | \n  v1 --- e3 --- v2\n</code></pre> <ul> <li>The <code>elem_type</code> of the quadrilateral cell, <code>c1</code>, is <code>SHELL4</code></li> <li>It comprises of four vertices (i.e. <code>v1</code>, <code>v2</code>, <code>v3</code>, <code>v4</code>)</li> <li>It has six edges sidesets. The first two edge sidesets form a plane and the remaining   four edge sidesets are lines as follows:</li> <li><code>e1</code>: an oriented plane formed by <code>v1</code>, <code>v2</code>, <code>v3</code>, <code>v4</code> (not shown above)</li> <li><code>e2</code>: an oriented plane formed by <code>v1</code>, <code>v4</code>, <code>v3</code>, <code>v2</code> (not shown above)</li> <li><code>e3</code>: Line from <code>v1</code> to <code>v2</code></li> <li><code>e4</code>: a directed line from <code>v2</code> to <code>v3</code></li> <li><code>e5</code>: a directed line from <code>v3</code> to <code>v4</code></li> <li><code>e6</code>: a directed line from <code>v4</code> to <code>v1</code></li> </ul>"},{"location":"developer/mesh.html#example-mesh-with-mixed-element-types","title":"Example mesh with mixed element types","text":"<p>An example of mesh that comprises of:</p> <ul> <li>12 cells with 4 quadrilaterals and 8 triangles</li> <li>14 vertices</li> <li>Five edge sidesets</li> <li>Right boundary</li> <li>Left boundary</li> <li>Top boundary</li> <li>Bottom boundary</li> <li>River</li> </ul> <p>The <code>.exo</code> mesh file uses NetCDF. Cells of different types (e.g. quadrilaterals and triangles) must be saved as two different data fields in the <code>.exo</code> file (e.g <code>connect1</code> for quadrilateral and <code>connect2</code> for triangles.</p> <pre><code> # quadrilateral cells\n connect1 =\n  1, 2, 6, 5,\n  3, 4, 8, 7,\n  5, 6, 10, 9,\n  7, 8, 12, 11 ;\n\n# triangular cells\n connect2 =\n  2, 3, 13,\n  3, 7, 13,\n  7, 6, 13,\n  6, 2, 13,\n  6, 7, 14,\n  7, 11, 14,\n  11, 10, 14,\n  10, 6, 14 ;  \n</code></pre> <p>Each edge sideset is defined via two data fields:</p> <ul> <li><code>elem_ss&lt;ID&gt;</code>: Corresponds to the cell (or element) ID</li> <li><code>side_ss&lt;ID&gt;</code>: Correponds to the edge sideset</li> </ul> <p>The five edge sidesets for the above mesh are defined as</p> <pre><code> # right boundary\n elem_ss1 = 2, 4 ;\n side_ss1 = 4, 4 ;\n\n # left boundary\n elem_ss2 = 1, 3 ;\n side_ss2 = 6, 6 ;\n\n # top boundary\n elem_ss3 = 3, 11, 4 ;\n side_ss3 = 5, 3, 5 ;\n\n # bottom boundary\n elem_ss4 = 1, 5, 2 ;\n side_ss4 = 3, 3, 3 ;\n\n # river\n elem_ss5 = 4, 9, 9, 8, 8 ;\n side_ss5 = 3, 4, 5, 5, 4 ;\n</code></pre>"},{"location":"developer/mesh.html#dmplex-hdf5-v300","title":"DMPlex HDF5 v3.0.0","text":"<p>Before understanding the DMPlex's HDF5 storage version v3.0.0 (i.e. <code>-dm_plex_view_hdf5_storage_version 3.0.0</code>), it is important to understand how DMPlex number mesh elements.</p>"},{"location":"developer/mesh.html#dmplex-mesh-numbering-for-a-serial-run","title":"DMPlex mesh numbering for a serial run","text":"<p>DMPlex uses 0-based numbering. The mesh elements are numbered in the following order:</p> <ol> <li>Cells</li> <li>Vertices</li> <li>Edges. </li> </ol> <p>For the mesh shown in the figure, DMPlex assigns IDs for cells, vertices, and edges thus:</p> <ul> <li>Cell ID: <code>0</code>-<code>11</code></li> <li>Vertex ID: <code>12</code> to <code>25</code></li> <li>Edge ID: <code>26</code> to <code>50</code></li> </ul> <p></p> <pre><code>#\n# ncells    = Number of cells\n#           = nquad (number of quadrilaterals) + ntri (number of trinagles)\n#           = 4 + 8 = 12\n#\n# nvertices = Number of vertices = 14\n#\n# nedges    = Number of unique edges\n#           = nedges_internal (number of internal edges) + nedges_bnd (number of boundary edges)\n#           = 15 + 10 = 25\n#\n# ntotal    = ncells + nvertices + nedges\n#           = 12 + 14 + 25 = 51\n\n\u251c\u2500\u2500 topologies (G)\n    \u251c\u2500\u2500 Parallel Mesh (G) Attributes: (1) coordinateDMName (STRING), (2) coordinatesName (STRING)\n        \u251c\u2500\u2500 dms (G)\n        |   \u251c\u2500\u2500 coordinateDM (G)\n        |       |\n        |       \u251c\u2500\u2500 order (D, INTEGER, size = ntotal)\n        |       |\n        |       \u251c\u2500\u2500 section (G) Attributes: (1) hasConstraints (INTEGER) (2) includesConstraint (INTEGER), (3) numFields (INTEGER)\n        |       |   |\n        |       |   \u251c\u2500\u2500 atlasDof (D, INTEGER, size = ntotal) [zeros(0:ncells,1); 3*ones(nvertices,1);   zeros(nedges,1)]\n        |       |   |\n        |       |   \u251c\u2500\u2500 atlasOff (D, INTEGER, size = ntotal) [zeros(0:ncells,1); [0:3:(nvertices-1)*3]; ones(nedges,1)*nvertices*3]\n        |       |   |\n        |       |   \u251c\u2500\u2500 field0 (G) Attributes: (1) fieldComponents (INTEGER) (2) fieldName (STRING) (3) hasConstraints (INTEGER) (4) includesConstraint (INTEGER)\n        |       |       |\n        |       |       \u251c\u2500\u2500 atlasDof   (D, INTEGER, size = ntotal) [zeros(0:ncells,1); 3*ones(nvertices,1);   zeros(nedges,1)]\n        |       |       \u251c\u2500\u2500 atlasOff   (D, INTEGER, size = ntotal) [zeros(0:ncells,1); [0:3:(nvertices-1)*3]; ones(nedges,1)*nvertices*3]\n        |       |       |\n        |       |       \u251c\u2500\u2500 component0 (G) Attribute (1) componentName (STRING)\n        |       |       \u251c\u2500\u2500 component1 (G) Attribute (1) componentName (STRING)\n        |       |       \u251c\u2500\u2500 component2 (G) Attribute (1) componentName (STRING)\n        |       |\n        |       \u251c\u2500\u2500 vecs (G)\n        |          \u251c\u2500\u2500 coordinates (G) Attribute (1) blockSize\n        |             |\n        |             \u251c\u2500\u2500 coordinates (D, FLOAT, size = 3 * nvertices) Note: Each vertex has 3 coordinates in x,y,z\n        |\n        \u251c\u2500\u2500 labels\n        |   \u251c\u2500\u2500 Cell Sets (G)\n        |   |  \u251c\u2500\u2500 1 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER, size = ncells) [0:ncells-1]\n        |   |\n        |   \u251c\u2500\u2500 Face Sets (G, OPTIONAL)\n        |   |  \u251c\u2500\u2500 1 (G)\n        |   |  |  \u251c\u2500\u2500 indicies (D, INTEGER) (e.g. [31 37] for right boundary)\n        |   |  |\n        |   |  \u251c\u2500\u2500 2 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER) (e.g. [28 36] for left boundary)\n        |   |  |\n        |   |  \u251c\u2500\u2500 3 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER) (e.g. [35 38 49] for top boundary)\n        |   |  |\n        |   |  \u251c\u2500\u2500 4 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER) (e.g. [26 30 40] for bottom boundary)\n        |   |  |\n        |   |  \u251c\u2500\u2500 5 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER) (e.g. [32 42 45 46 47] for river)\n        |   |\n        |   \u251c\u2500\u2500 boundary_edges (G)\n        |   |  \u251c\u2500\u2500 1 (G)\n        |   |     \u251c\u2500\u2500 indicies (D, INTEGER, size = nedges_bnd)\n        |   |\n        |   \u251c\u2500\u2500 celltype (G)\n        |      \u251c\u2500\u2500 0 (G)\n        |      |  \u251c\u2500\u2500 indicies (D, INTEGER, size = num_verrtices) [ncells:ncells+nvertices-1]\n        |      |\n        |      \u251c\u2500\u2500 1 (G)\n        |      |  \u251c\u2500\u2500 indicies (D, INTEGER, size = num_edges)     [ncells+nvertices:ncells+nvertices+nedges-1]\n        |      |\n        |      \u251c\u2500\u2500 3 (G, OPTIONAL, TRIANGULAR)\n        |      |  \u251c\u2500\u2500 indicies (D, INTEGER, size = num_tri)       [nquads:nquads+ntri-1]\n        |      |\n        |      \u251c\u2500\u2500 4 (G, OPTIONAL, QUADRILATERALS)\n        |         \u251c\u2500\u2500 indicies (D, INTEGER, size = num_quads)     [0:nquads]\n        |\n        \u251c\u2500\u2500 topology (G) Attributes: (1) cell_dim (INTEGER) (2) depth (INTEGER)\n            |\n            \u251c\u2500\u2500 permutation (D, INTEGER, size = 3)\n            |\n            \u251c\u2500\u2500 strata (G)\n               \u251c\u2500\u2500 0 (G)\n               |   \u251c\u2500\u2500 cone_sizes  (D, INTEGER, size = num_vertices)\n               |   \u251c\u2500\u2500 cones       (D, INTEGER)\n               |   \u251c\u2500\u2500 orientation (D, INTEGER)\n               |\n               \u251c\u2500\u2500 1 (G)\n               |   \u251c\u2500\u2500 cone_sizes  (D, INTEGER, size = num_edges)\n               |   \u251c\u2500\u2500 cones       (D, INTEGER, size = 2 * num_edges)\n               |   \u251c\u2500\u2500 orientation (D, INTEGER, size = 2 * num_edges)\n               |\n               \u251c\u2500\u2500 2 (G)\n                   \u251c\u2500\u2500 cone_sizes  (D, INTEGER, size = ncells)\n                   \u251c\u2500\u2500 cones       (D, INTEGER, size = 4 * nquads + 3 * ntri)\n                   \u251c\u2500\u2500 orientation (D, INTEGER, size = 4 * nquads + 3 * ntri)\n</code></pre>"},{"location":"developer/mesh.html#domain-decomposition","title":"Domain Decomposition","text":"<p>Below is the decomposition of the example mesh with mixed element types across two MPI ranks.</p> <p></p> <p>The physics in RDycore is currently implmented in two versions:</p> <ol> <li>A PETSc only implementation without support for libCEED</li> <li>An implementation with support for libCEED</li> </ol> <p>In the libCEED version of RDycore, the edges between an owned and ghost cell are only present on the rank with a lower ID.</p>"},{"location":"developer/operators.html","title":"Composite Operator Structure","text":"<p>In order to implement the physics necessary for assessing risks surrounding compound flooding, RDycore allows the construction of operators that solve sets of equations using sub-operators as building blocks. Each of these sub-operators is implemented by either a <code>CeedOperator</code> or a set of functions implementing a PETSc right-hand-side (RHS) function.</p>"},{"location":"developer/operators.html#what-is-an-operator","title":"What is an operator?","text":"<p>For the purposes of our discussion, an operator transforms a solution vector at a time \\(t\\) to its time derivative, using the language of ordinary differential equations. A linear operator \\(\\mathcal{L}\\) represents a linear transformation, which can be thought of like a matrix:</p> \\[ \\frac{\\partial \\mathbf{u}}{\\partial t} = \\mathcal{L}(t)\\mathbf{u} \\] <p>Meanwhile, a nonlinear operator \\(\\mathcal{N}\\) behaves like a function:</p> \\[ \\frac{\\partial \\mathbf{u}}{\\partial t} = \\mathcal{N}(t, \\mathbf{u}) \\] <p>For example, in a conservative system of equations solved by the finite volume method</p> \\[ \\frac{\\partial \\mathbf{u}}{\\partial t} + \\nabla\\cdot\\vec{\\mathbf{F}}(\\mathbf{u}) = \\mathbf{S}(t, \\mathbf{u}), \\] <p>the relevant nonlinear operator can be written</p> \\[ \\mathcal{N}(t, \\mathbf{u}) = -\\nabla\\cdot\\vec{\\mathbf{F}}(\\mathbf{u}) + \\mathbf{S}(t, \\mathbf{u}). \\] <p>Each sub-operator within an operator assumes responsibility for part of this calculation. Let's look at some examples.</p>"},{"location":"developer/operators.html#shallow-water-equations-swe-operator","title":"Shallow Water Equations (SWE) operator","text":"<p>This operator consists of the following sub-operators, each of which operates on all 3 components of a solution vector \\(\\mathbf{u} = [h, hu, hv]^T\\):</p> <ol> <li>an \"interior flux operator\" that computes fluxes on edges separating pairs of    cells on the interior of the domain</li> <li>a \"boundary flux operator\" for each boundary on the domain that computes    fluxes on boundary edges using adjoining interior cells and values assigned     to each boundary</li> <li>a \"source operator\" that computes source terms on the interior of the domain</li> </ol>"},{"location":"developer/operators.html#sediment-transport-operator","title":"Sediment Transport operator","text":""},{"location":"developer/operators.html#ceed-implementation","title":"CEED implementation","text":""},{"location":"developer/organization.html","title":"RDycore Code Structure and Organization","text":"<p>In this section, we describe the organization of RDycore's source files. We have attempted to group functions and data types together into subsystems that can be easily understood separately from one another.</p> <p>Because RDycore's behavior is determined entirely by input parameters specified in the YAML input format, it's a good idea to familiarize yourself with this format as you read this section.</p>"},{"location":"developer/organization.html#a-brief-tour-of-rdycores-source-tree","title":"A Brief Tour of RDycore's Source Tree","text":"<p>The root level of the RDycore source tree contains a <code>README.md</code> file, a <code>CMakeLists.txt</code> file that defines the build system, and some configuration files for documentation and tooling.</p> <p>There are several folders at the root of the source tree:</p> <pre><code>+ RDyore +- .github/workflows\n         |\n         +- cmake\n         |\n         +- config\n         |\n         +- docs\n         |\n         +- driver\n         |\n         +- external\n         |\n         +- include\n         |\n         +- share\n         |\n         +- src\n         |\n         +- tools\n</code></pre> <ul> <li><code>.github/workflows</code>: workflows   that support our GitHub Continuous Integration   Environment</li> <li><code>cmake</code>: CMake scripts   that support the build system, testing, etc.</li> <li><code>config</code>: shell scripts   to help with running RDycore on our target platforms</li> <li><code>docs</code>: Markdown source   files for our mkdocs-based   documentation</li> <li><code>driver</code>: C and Fortran   driver programs, including the standalone RDycore drivers and a few other   development tools</li> <li><code>external</code>: third-   party libraries used by RDycore that aren't provided by PETSc</li> <li><code>include</code>: the   <code>rdycore.h.in</code> template that generates the <code>rdycore.h</code> API header file, and   all private header files (located within the <code>private</code> subfolder)</li> <li><code>share</code>: data files for   initial conditions, material properties, and unstructured grids (used mainly   for testing)</li> <li><code>src</code>: the source code for   RDycore</li> <li><code>tools</code>: miscellaneous   tools and scripts for building and deploying Docker images</li> </ul> <p>Take a look at each of these folders to familiarize yourself with their contents. In particular, the <code>src</code> folder has a few important subfolders:</p> <ul> <li><code>src/f90-mod</code>: the RDycore Fortran module that mirrors the C library's   capabilities</li> <li><code>src/swe</code>: functions and data structures specific to the solution of the   2D shallow water equations</li> <li><code>src/sediment</code>: functions and data structure specific to the solution of   the 2D shallow water equations coupled with diffusion-diffusion equation   for sediment dynamics</li> <li><code>src/tests</code>: unit tests for subsystems within RDycore</li> </ul> <p>The private headers in the <code>include</code> folder contain definitions of opaque types and functions that are helpful throughout RDycore but are not part of the API.</p> <p>The <code>driver</code> folder also has its own <code>tests</code> subfolder that defines tests that run the standalone drivers and perform convergence tests for selected problems.</p>"},{"location":"developer/organization.html#the-rdycore-object-and-its-lifecycle","title":"The RDycore Object and its Lifecycle","text":"<p>RDycore (the \"river dynamical core\") is represented in code by a data structure called <code>RDy</code>, declared as an opaque type in include/rdycore.h. It is defined in include/private/rdycoreimpl.h. In this section, we describe how to manipulate <code>RDy</code> to set up and run simulations. It may be helpful to refer to the standalone C driver (and or the corresponding Fortran driver) as you read this section.</p> <ol> <li>Initialization</li> </ol> <p>Before RDycore can be used in any program, the supporting systems must be initialized with a call to <code>RDyInit</code>:</p> <pre><code>  // initialize RDycore subsystems\n  PetscCall(RDyInit(argc, argv, helpString));\n</code></pre> <p>This function accepts the <code>argc</code> and <code>argv</code> command line argument parameters accepted by any C program, plus a string printed to display help/usage information.</p> <p>Next, create an <code>RDy</code> object, passing it an MPI communicator, the path to a YAML input file, and the pointer to the desired <code>RDy</code> object:</p> <pre><code>  // create an RDy on the given communicator with the given input\n  RDy rdy;\n  PetscCall(RDyCreate(MPI_COMM_WORLD, \"my-input.yaml\", &amp;rdy));\n</code></pre> <p>This only creates the object--it does not read input or allocate any resources for the problem described within the input.</p> <ol> <li>Setup</li> </ol> <p>To read the input file and ready your <code>RDy</code> object to run the simulation defined therein, call <code>RDySetup</code>:</p> <pre><code>  // read input and set up the dycore\n  PetscCall(RDySetup(rdy));\n</code></pre> <p>After this call, you're ready to run a simulation. You can also all any query or utility functions on your <code>RDy</code> object to do whatever you need for your own simulation. For example, you might need information about the unstructured grid, or perhaps you are specifying specific boundary values for a Dirichlet boundary condition. See the API header file for all the possibilities.</p> <ol> <li>Timestepping</li> </ol> <p>The simplest way to start running your simulation after setup is to run <code>RDyAdvance</code> (which takes a single step) within a <code>while</code> loop that uses <code>RDyFinished</code> as termination condition:</p> <pre><code>  // run the simulation to completion\n  while (!RDyFinished(rdy)) {\n    // ... pre-step logic here ...\n\n    // advance the simulation by a single step\n    PetscCall(RDyAdvance(rdy));\n\n    // ... post-step logic here ...\n  }\n</code></pre> <p>If you look in the standalone C driver, you can see various pre- and post-step logic to accommodate data transfer, restarts, etc.</p> <ol> <li>Finalization</li> </ol> <p>At the end of an RDycore-enabled program, you must destroy the <code>RDy</code> object with a call to <code>RDyDestroy</code>:</p> <pre><code>  // destroy the dycore\n  PetscCall(RDyDestroy(&amp;rdy));\n</code></pre> <p>Finally, call <code>RDyFinalize</code> to reclaim all resources used by RDycore and its subsystems:</p> <pre><code>  // clean up\n  PetscCall(RDyFinalize());\n</code></pre>"},{"location":"developer/organization.html#computational-domain","title":"Computational Domain","text":"<p>RDycore solves equations on a topologically-two-dimensional domain with topography represented by an elevation coordinate \\(z(x, y)\\).</p> <p>RDycore uses two objects to represent the computional domain:</p> <ul> <li>DMPlex: a PETSc data structure   that stores the minimum set of information needed to define an unstructured   grid</li> <li>RDyMesh:   An RDycore-specific data structure (implementation here)   that stores data for cells, edges, and vertices, constructed using the   <code>DMPlex</code> object</li> </ul> <p>Both of these objects are created by a call to RDySetup. The <code>RDyMesh</code> object is a simple container with</p> <ul> <li>metadata like numbers of cells, edges, vertices</li> <li>a <code>cells</code> field that stores cell data in an <code>RDyCells</code> data structure</li> <li>an <code>edges</code> field that stores edge data in an <code>RDyEdges</code> data structure</li> <li>a <code>vertices</code> field that stores vertex data in an <code>RDyVertices</code> data structure</li> <li>metadata useful for output/visualization</li> </ul> <p>The domain is partitioned into disjoint regions, each of which consists of a set of contiguous cells, usually triangles or quads. Additionally, the domain is bounded by one or more boundaries, each of which consists of a set of edges (which can be thought of as two-dimensional \"faces\"). We describe how regions and boundaries work below.</p>"},{"location":"developer/organization.html#regions","title":"Regions","text":"<p>When a mesh file is read to create a <code>DMPlex</code> object during RDySetup, DMLabel objects are created that represent disjoint sets of cells. Each cell set represents a region. From each label/cell set, RDycore constructs an RDyRegion, which is basically a named array of local cell IDs.</p> <p>RDycore then uses information in the YAML input file to associate initial condition and source data with each region by name. This process is implemented in the <code>InitRegions</code> function (https://github.com/RDycore/RDycore/blob/main/src/rdysetup.c#L182).</p>"},{"location":"developer/organization.html#boundaries","title":"Boundaries","text":"<p>Similarly to regions, the <code>DMPlex</code> object created during RDySetup constructs <code>DMLabel</code> objects represents disjoint sets of edges, each of which represents a boundary. From each label/edge set, RDycore constructs an RDyBoundary, a named array of local edge IDs.</p> <p>RDycore then uses information in the YAML input file to associate boundary condition data with each boundary by name. This process is implemented in the <code>InitBoundaries</code> function, which is called in <code>RDySetup</code>.</p>"},{"location":"developer/organization.html#operators","title":"Operators","text":"<p>For purposes of our discussion, an \"operator\" is a mathematical construct for computing interior and boundary fluxes and source terms. Each operator is represented by a specific data structure associated with functions that implement its operations.</p>"},{"location":"developer/organization.html#overview","title":"Overview","text":"<p>RDycore uses two different but numerically equivalent technical approaches for solving its governing equations:</p> <ol> <li>A CPU-only version that uses PETSc. We refer to this version as the PETSc version.</li> <li>A CPU and GPU supported version that uses PETSc and CEED. We refer to this version as the CEED version.</li> </ol> <p>The PETSc version is mainly used to troubleshoot our CEED version. Both of the RDycore versions are in wrapped in a C struct called <code>Operator</code> defined in the rdyoperatorimpl.h.</p> <p>The CEED version of the operator code has two parts:</p> <ul> <li>\"host\" code that runs on the CPU and dispatches calls to the \"device\" (a CPU   or GPU, depending on your runtime configuration) to create, update,   manipulate, and destroy the operator</li> <li>\"device\" code that performs the mathematical operators associated with the   operator using the libceed   exascale library.</li> </ul> <p>To make the PETSc version of the code be similar to the CEED version, the PETSc operator also has two parts that are similar to the CEED version. However, the PETSc version of the operator code only runs on a CPU.</p> <p>The <code>AddPhysicsOperators()</code> in <code>operator.c</code> sets up the operators for the PETSc or CEED version of the RDycore. Furthermore, each version of operators sets up physcis-specific (i.e., SWE or sediment dynamics) operators.</p> <p>NOTE: at the time of writing, the physics in RDycore's operators supports the following configurations: (1) SWE: PETSc and CEED version and (2) Sediment Dynamics: PETSc version.</p>"},{"location":"developer/organization.html#shallow-water-equations-swe-operators","title":"Shallow Water Equations (SWE) operators","text":"<p>All shallow-water-equations-specific code lives within the swe source subfolder. The SWE operators are created and configured by <code>AddPetscFlowOperators</code> and <code>AddCeedFlowOperators</code> functions for PETSc and CEED, respecitively. These two functions live in <code>operator.c</code>. The interface for the \"SWE operator\" is visible in the private header rdysweimpl.h. Few details about the the PETSc and CEED version is as follows:</p> <ol> <li> <p>PETSc version: The creation of operators and the physics implementation lives in <code>swe/swe_petsc.c</code></p> </li> <li> <p>CEED version: The creation of operators and the physics implementation lives in two separate files. The creation operators is defined within <code>swe/swe_ceed.c</code>, while the header file <code>swe/swe_ceed_impl.h</code> defines the physics implementation. The header file defines inline <code>CeedQFunction</code>s that run on the device.</p> </li> </ol> <p>For both PETSc and CEED version, we implement the following SWE operators:</p> <ul> <li> <p>Riemann Flux operator: computes finite-volume fluxes between interior   cells and on the boundaries, according to specified boundary conditions.   In the CEED implementation, these two operators (for interior and boundary fluxes)   are combined into a composite operator   that is called using in-place device data. In the PETSc version, these operators   are implemented by CPU code that is applied sequentially to relevant data.</p> </li> <li> <p>Source operator: computes the source term for the shallow water equations</p> </li> </ul>"},{"location":"developer/organization.html#sediment-dynamics-operators","title":"Sediment Dynamics operators","text":"<p>The sediment dynamics-specific code, which comparises of SWE coupled with advection-diffusion equation, lives within the sediment source subfolder. Presently, only the PETSc version of the operator is implemented via <code>AddPetscSedimentOperators</code> that lives in <code>operator.c</code>.</p>"},{"location":"developer/organization.html#input","title":"Input","text":"<p>The parsing of input is dispatched from RDySetup and implemented in ReadConfigFile. At the top of <code>yaml_input.c</code>, several structs are defined that represent a YAML \"schema\". In this \"schema,\" each struct represents a YAML mapping object, with fields in the mapping corresponding to fields in the struct. Accordinglhy, YAML arrays within mappings are represented by array fields.</p> <p>For a more detailed explanation of how this YAML schema is parsed, see the libcyaml documentation.</p>"},{"location":"developer/organization.html#output","title":"Output","text":"<p>RDycore can produce output for visualization, as well as diagnostic output helpful for troubleshooting and debugging.</p>"},{"location":"developer/organization.html#visualization","title":"Visualization","text":"<p>RDycore supports two visualizable output formats:</p> <ul> <li>XDMF: an ancient,   marginally-supported format, popular in the earth science community, that   stores data in HDF5 files and metadata in XML files</li> <li>CFD General Notational System (CGNS): a standard   format with lots of traction in the CFD community but less visibility within   the earth science community</li> <li>PETSc's binary output format, which is better than nothing but probably not   very full-featured.</li> </ul> <p>The writing of XDMF files is implemented in <code>xdmf_output.c</code> in the <code>WriteXDMFOutput</code> function. CGNS and binary output are handled mostly by PETSc's built-in output machinery.</p> <p>All output functions are registered using PETSc's TSMonitor feature and called in <code>RDyAdvance</code> (within rdyadvance.c) at the frequency specified in the YAML input file.</p>"},{"location":"developer/organization.html#diagnostics-time-series","title":"Diagnostics: time series","text":"<p>RDycore can write out time series data useful for debugging simulations. Currently, the only quantity that can be recorded as a time series is the \"boundary flux\"--the total flux through the domain boundary, which is needed to account for mass non-conservation in simulations with open boundaries.</p> <p>Time series data are accumulated and written by logic in <code>time_series.c</code>. The function <code>InitTimeSeries</code> initializes this subsystem, and is called in <code>RDyAdvance</code>.</p> <p>These time series diagnostics are invasive, and can negatively affect simulation performance, particularly when using GPUs. Therefore they are intended only for debugging and troubleshooting.</p>"},{"location":"developer/organization.html#checkpoints-and-restarts","title":"Checkpoints and Restarts","text":"<p>The writing of checkpoint files (which store all state data necessary to restart a simulation) and the process of restarting a previously-running simulation are largely handled by PETSc:</p> <ul> <li><code>InitCheckpoints</code> (defined in checkpoint.c   sets up a TSMonitor that   calls the <code>WriteCheckpoint</code> function at an interval specified in the YAML   input file. This function is called in <code>RDySetup</code>.</li> <li><code>ReadCheckpointFile</code> (also defined in <code>checkpoint.c</code>) reads the checkpoint   file (in a format specified within the YAML input. This function is called   in <code>RDySetup</code> if the input file specifie\u0455 that a simulation should be   restarted.</li> </ul>"},{"location":"developer/organization.html#running-ensembles","title":"Running Ensembles","text":"<p>RDycore can run ensembles, which are sets of concurrently-running simulations (\"ensemble members\") with variations in selected input parameters. RDycore uses an extremely simple mechanism to run these simulations within a single MPI job:</p> <ul> <li>on initialization, RDycore splits its \"world\" communicator into a number of   smaller, communicators of equal size</li> <li>each of these smaller communicators is assigned to a single ensemble member</li> <li>each ensemble member is configured according to the ensemble specification   in the YAML input file</li> <li>all ensemble members are run concurrently to completion</li> </ul> <p>Currently, ensemble calculations only run ensemble members, possibly generating member-specific output. No post-processing or analysis has been implemented, though it would likely be simple to do so.</p>"},{"location":"developer/organization.html#ensemble-member-configuration","title":"Ensemble member configuration","text":"<p>The data for each ensemble member is listed explicitly in the ensemble section of the YAML input specification. All parameters for ensemble members override the corresponding parameters in other sections of the file. This logic is implemented in the <code>ConfigEnsembleMember</code> function within ensemble.c.</p>"},{"location":"developer/organization.html#support-for-fortran","title":"Support for Fortran","text":"<p>A Fortran version of the public C interface is available in an <code>rdycore</code> Fortran module in the <code>src/f90-mod</code> directory. This module is hand-written and uses the Fortran 2003 <code>iso_c_binding</code> standard intrinsic module to map C functions to equivalent Fortran subroutines and functions, and defines appropriate data types.</p> <p>The mapping from a C function to a Fortran subroutine (or function) is accomplished in two parts:</p> <ol> <li> <p>A C function is made available to Fortran by defining a Fortran function    within an <code>interface</code> block that uses a <code>bind(C)</code> annotation specifying the    case-sensitive name of the C function. All data types in this Fortran    function must correspond to supported C data types via the <code>iso_c_binding</code>    module. The function returns an integer corresponding to the <code>PetscErrorCode</code>    return type of the C function. We refer to such a function as a \"C-bound    Fortran function\".</p> </li> <li> <p>A Fortran \"wrapper\" subroutine is defined that calls the C-bound Fortran    function defined in item 1. This subroutine follows the PETSc convention in    which the last argument (<code>ierr</code>) gets the return value of the C-bound Fortran    function.</p> </li> </ol> <p>For example, let's take a look at the Fortran function for <code>RDyCreate</code>, which calls the C function <code>RDyCreateF90</code>. This separate C function is required because <code>RDyCreate</code> accepts an <code>MPI_Comm</code> input parameter, and Fortran uses integers for MPI communicators.</p> <p>First, we create a C-bound Fortran function <code>rdycreate_</code> and associate it with the C function <code>RDyCreateF90</code> within the <code>interface</code> block near the top of <code>f90-mod/rdycore.F90</code>:</p> <pre><code>  interface\n    ...\n    integer(c_int) function rdycreate_(comm, filename, rdy) bind(c, name=\"RDyCreateF90\")\n      use iso_c_binding, only: c_int, c_ptr\n      integer,            intent(in)  :: comm\n      type(c_ptr), value, intent(in)  :: filename\n      type(c_ptr),        intent(out) :: rdy\n    end function\n    ...\n  end interface\n</code></pre> <p>Then we define a subroutine <code>RDyCreate</code> that calls <code>rdycreate_</code> and sets <code>ierr</code> to its return value:</p> <pre><code>  subroutine RDyCreate(comm, filename, rdy_, ierr)\n    use iso_c_binding, only: c_null_char\n    character(len=1024), intent(in) :: filename\n    integer,   intent(in)  :: comm\n    type(RDy), intent(out) :: rdy_\n    integer,   intent(out) :: ierr\n\n    integer                      :: n\n    character(len=1024), pointer :: config_file\n\n    n = len_trim(filename)\n    allocate(config_file)\n    config_file(1:n) = filename(1:n)\n    config_file(n+1:n+1) = c_null_char\n    ierr = rdycreate_(comm, c_loc(config_file), rdy_%c_rdy)\n    deallocate(config_file)\n  end subroutine\n</code></pre> <p>Notice that we have to do some things to construct a NULL-terminated C string for the filename with a character array and <code>c_null_char</code>, and then pass a pointer to this array with <code>c_loc</code>. This is how things are done with Fortran's <code>iso_c_binding</code> module, which you can learn about in the link at the top of this section.</p> <p>Whenever a new C function is added to the public interface in <code>rdycore.h</code>, these two corresponding Fortran items must be added to the template from which it is generated to support its use in Fortran.</p>"},{"location":"developer/organization.html#special-considerations","title":"Special considerations","text":"<ul> <li>C pointers: Perhaps counterintuitively, C pointers must be passed by value   to Fortran-bound C functions. In other words, any argument of type <code>type(c_ptr)</code>   must have the <code>value</code> attribute and <code>intent(in)</code>. You can think of a pointer   as a memory location, which is morally equivalent to an integer of the   appropriate size. The <code>intent(in)</code> expresses that the pointer itself remains   unchanged even if the data it points to is modified by the function.   NOTE: an <code>RDy</code> C object is expressed as a C pointer in the Fortran module.</li> <li>C primitives: Because C passes arguments to functions by value and Fortran   by reference, it is necessary to add the <code>value</code> attribute to any parameter   in a C-bound Fortran function that has a non-pointer C type. This includes   most <code>intent(in)</code> primitive parameters in C-bound Fortran functions. Note   that <code>intent(out)</code> parameters in these functions must necessarily be pointers   in C functions, so they must not have the <code>value</code> attribute.</li> <li>Enumerated types: An enumerated type in C can be mapped to Fortran as a   set of related integer parameters. See, for example, the way time units   are expressed in the <code>rdycore</code> Fortran module.</li> <li>PETSc types: PETSc types like <code>Vec</code> are passed to C-bound Fortran   functions as <code>PetscFortranAddr</code> with the <code>value</code> attribute and <code>intent(in)</code>.   This is very similar to the way we treat C pointers, with some magic PETSc   pixie dust sprinkled on it to satisfy conditions required by PETSc.</li> </ul>"},{"location":"developer/style.html","title":"RDycore (C) Style Guide","text":"<p>Here we provide a simple style guide for C code within the RDycore library. This style guide applies mainly to source code within the RDycore C library itself. The corresponding Fortran library is a thin hand-written wrapper around the C library that doesn't leave much room for \"style,\" so there is no Fortran style guide.</p> <p>This style guide is very short compared to many others, since C is a very small language and most formatting conventions (whitespace, lengths of lines, placement of curly braces) are enforced via tools and not humans. Here, we focus mainly on those conventions that need the attention of RDycore team members and other contributors.</p>"},{"location":"developer/style.html#style-conventions","title":"Style Conventions","text":"<p>RDycore's conventions are based on those in the PETSc Style and Usage Guide, with the following deviations:</p> <ul> <li>we allow the use of variable-length arrays (VLAs)</li> <li>we use standard header guards instead of the nonstandard <code>#pragma once</code>   mechanism</li> <li>we prefer C++-style code comments (<code>//</code>) to C-style comments (<code>/* */</code>) even   for multi-line comments</li> <li>we use C conventions for logical expressions, e.g.<ul> <li><code>if (cond)</code> instead of <code>if (cond == PETSC_TRUE)</code></li> <li><code>if (!cond)</code> instead of <code>if (cond == PETSC_FALSE)</code></li> <li><code>if (foo)</code> instead of <code>if (foo != NULL)</code> for pointers</li> <li><code>if (!foo)</code> instead of <code>if (foo == NULL)</code> for pointers</li> </ul> </li> </ul> <p>These deviations reflect certain facts about RDycore relative to PETSc:</p> <ul> <li>RDycore targets fewer systems than PETSc</li> <li>RDycore is much small codebase with fewer contributors than PETSc</li> <li>RDycore does not support the use of C++</li> </ul> <p>We summarize the most important conventions below (in alphabetical order).</p>"},{"location":"developer/style.html#functions","title":"Functions","text":"<p>Following the PETSc approach, all function bodies must be surrounded by the <code>PetscFunctionBegin</code> and <code>PetscFunctionReturn</code> macros. Try to write short functions, but avoid breaking up a function if doing so would introduce undue complexity, such as passing several variables around or introducing otherwise unnecessary abstractions.</p> <p>Accordingly, almost all functions in RDycore return a <code>PetscErrorCode</code> indicating success or failure, and all calls to these functions are enclosed within the <code>PetscCall</code> macro, e.g.</p> <pre><code>  PetscCall(RDyAdvance(rdy));\n</code></pre> <p>Function inputs and outputs are passed as arguments to a function. Because C passes arguments by value and not by reference (like Fortan), output parameters are typically pointers.</p>"},{"location":"developer/style.html#petsc-data-types","title":"PETSc Data Types","text":"<p>We use data types defined by PETSc, which are configured according to RDycore's build parameters:</p> <ul> <li><code>PetscInt</code> is a 32-bit or 64-bit integer, depending on whether your PETSc   installation is configured to use 32-bit or 64-bit indices. Use this for all   integers except those transmitted via MPI (see below).</li> <li><code>PetscMPIInt</code> is a 32-bit integer corresponding to the <code>MPI_INT</code> type, and   should be used for all integers in MPI messages, even in 64-bit builds.</li> <li><code>PetscReal</code> represents all real-valued quantities (usually double precision)</li> <li><code>PetscBool</code> is PETSc's boolean type, which assumes one of the values   <code>PETSC_TRUE</code> or <code>PETSC_FALSE</code>. It provides this type to provide compatibility   with older revisions of the C language that don't include the standard C   <code>bool</code> type.</li> </ul>"},{"location":"developer/style.html#header-files","title":"Header files","text":"<p>RDycore has one public header file that defines the interface for its C library: <code>rdycore.h</code>. This file is generated by CMake, which injects configuration information into the template <code>include/rdycore.h.in</code>. All other headers are private and declare functions and types used internally within the RDycore library.</p> <p>Functions declared in <code>rdycore.h</code> are annotated with the <code>PETSC_EXTERN</code> macro, which gives them external linkage, making them available to call outside of RDycore. Functions in private headers are annotated instead with <code>PETSC_INTERN</code>, giving them internal linkage and making them invisible to code outside of RDycore.</p> <p>All header files are located within the <code>include</code> directory. Private headers live in the <code>private</code> subdirectory. Take a look at these header files to get a sense of their structure.</p>"},{"location":"developer/style.html#naming","title":"Naming","text":"<ul> <li>Variable names: all variables (including fields within structs and   function pointers) use <code>snake_case</code> (e.g. <code>water_height</code>, <code>num_cells</code>)</li> <li>Function names: all functions using <code>PascalCase</code> (e.g. <code>RDySetup</code>,   <code>ApplyBoundaryCondition</code>)</li> </ul> <p>In all cases, avoid inscrutible names that use single letters or unconventional abbreviations unless their meaning is clear within the context in which they appear.</p>"},{"location":"developer/style.html#structs","title":"Structs","text":"<p>RDycore is developed using a \"structured programming\" approach in which related data are grouped into <code>struct</code>s and passed to functions by value.</p>"},{"location":"developer/style.html#style-enforcement-by-tools","title":"Style Enforcement by Tools","text":"<p>To check and enforce the style in the code within your Git workspace against the conventions we've adopted, you can use the following commands from your build directory:</p> <ul> <li><code>make format-c-check</code>: checks the source code in your workspace, reporting   success or failure depending on whether it conforms to our style conventions</li> <li><code>make format-c</code>: formats in place all relevant source code in your workspace,   enforcing our style conventions</li> </ul> <p>Sometimes an automated formatting tool disrupts the desired structure or layout of a particular section of code. In this case, you can exclude the section from auto-formatting by surrounding it with <code>// clang-format [on/off]</code> comments:</p> <pre><code>// clang-format on\n&lt;code section excluded from formatting&gt;\n// clang-format off\n</code></pre> <p>It's a good idea to run <code>make format-c</code> within a feature branch before creating a pull request. This ensures that the automated formatting check will pass.</p>"},{"location":"developer/tools.html","title":"RDycore Developer Tools","text":"<p>In this section we describe standalone programs and scripts that are helpful in the development of RDycore.</p>"},{"location":"developer/tools.html#the-standalone-c-and-fortran-drivers","title":"The Standalone C and Fortran Drivers","text":"<ul> <li>Standalone YAML input specification</li> </ul>"},{"location":"developer/tools.html#the-mms-c-and-fortran-drivers","title":"The MMS C and Fortran Drivers","text":"<ul> <li>MMS driver YAML input specification</li> </ul>"},{"location":"theory/index.html","title":"RDycore Theory Guide - Overview","text":"<p>This guide describes the mathematical and numerical approximations used by RDycore to model compound flooding.</p>"},{"location":"theory/index.html#notation","title":"Notation","text":""},{"location":"theory/index.html#two-types-of-vectors","title":"Two types of vectors","text":"<p>We write multi-component quantities in \\(\\mathbf{bold}\\), sometimes referring to them as vectors. For example, we refer this way to the solution vector \\(\\mathbf{U} = [h, hu, hv]^T\\). These multi-component quantities are vectors in the sense that they are used in matrix-vector expressions suitable for solving systems of equations. By convention, we write them as column vectors.</p> <p>By contrast, we write spatial vectors (those with \\(x\\) and \\(y\\) components aligned respectively with corresponding spatial axes) with arrows over their symbols, like the flow velocity \\(\\vec{u} = (u_x, u_y) = (u, v)\\). These are the vectors familiar to physical scientists. We write these as row vectors.</p> <p>Sometimes a multi-component quantity itself can be considered a spatial vector, such as the flux vector \\(\\mathbf{\\vec{F}} = (\\mathbf{F}_x, \\mathbf{F}_y),\\) where \\(\\mathbf{F}_x\\) and \\(\\mathbf{F}_y\\) are themselves multi-component quantities. We write these \"multi-component vector quantities\" in bold with arrows overhead.</p> <p>Distinguishing between these \"types\" of vectors allows us to make use of concepts from vector calculus such as divergence (\\(\\vec{\\nabla}\\cdot\\mathbf{\\vec{F}}\\)) and projections along vectors normal to surfaces (\\(\\mathbf{\\vec{F}}\\cdot\\vec{n}\\)). This distinction is often not made in numerical analysis, which can confuse the reader who is trying to unpack a complicated expression.</p>"},{"location":"theory/index.html#geometry","title":"Geometry","text":"<p>We use some elementary ideas from set theory to describe the geometry in our model formulation. Specifically:</p> <ul> <li>We deal exclusively with sets containing points in the plane. Any two sets \\(x\\) and \\(y\\) are equal \\((x = y)\\) if they contain exactly the same points.</li> <li>\\(\\varnothing\\) is the null set, which contains no points.</li> <li>We represent the 2D cells used by RDycore as closed sets in the plane. We typically write the cell \\(i\\) as \\(\\Omega_i\\), the set of all points contained within that cell, including those on its boundary.</li> <li>The boundary of a 2D cell consists of the faces (alternatively edges) that bound the cell. We write the boundary of the cell \\(\\Omega_i\\) as \\(\\partial\\Omega_i\\), the set of all points in each (piecewise linear) face attached to the cell, including its endpoints.</li> <li>The vertices of a 2D cell are the isolated points shared by adjacent faces in that cell. A triangular cell has 3 vertices, while a quadrilateral cell has 4.</li> <li>\\(p \\in x\\) indicates that the point \\(p\\) belongs to the set \\(x\\).</li> <li>\\(x \\subset y\\) indicates that the set \\(x\\) is a subset of the set \\(y\\). \\(x \\not\\subset y\\) indicates that \\(x\\) is not a subset of \\(y\\).</li> <li>\\(x \\bigcup y\\) indicates the union of two sets \\(x\\) and \\(y\\).</li> <li>\\(\\bigcup_i x_i\\) indicates the union of a number of indexed sets \\(x_i\\).</li> <li>\\(x \\bigcap y\\) indicates the intersection of two sets \\(x\\) and \\(y\\).</li> <li>\\(\\bigcap_i x_i\\) indicates the intersection of a number of indexed sets \\(x_i\\).</li> </ul> <p>Cells, faces, and vertices can be easily expressed in terms of these basic ideas:</p> <ul> <li>The intersection of two cells \\(i\\) and \\(j\\) (written \\(\\Omega_i \\bigcap \\Omega_j\\)), is the face separating those two cells, consisting of all points contained in both cells.</li> <li>We sometimes refer to a face \\(f \\in \\partial\\Omega_i\\), which reads \"face \\(f\\), which belongs to the boundary of cell \\(i\\).\"</li> <li>The intersection of two adjacent faces in a cell is a vertex of that cell, consisting of the single point common to those faces.</li> </ul> <p>The union of all cells \\(\\Omega_i\\) in a grid is the computational domain \\(\\Omega\\) over which the grid is defined. The boundary of this domain, which can be written \\(\\partial\\Omega\\) but which we also sometimes write as \\(\\Gamma\\) for clarity, is the set of all faces attached to only one cell.</p>"},{"location":"theory/sediment.html","title":"Sediment Transport","text":"<p>Our treatment of the transport of sediment is based on a model developed by Hairsine and Rose that accounts for size-selective sediment transport using a particle size distribution.</p>"},{"location":"theory/sediment.html#2-d-hairsine-rose-h-r-equations","title":"2-D Hairsine-Rose (H-R) Equations","text":"<p>The H-R equations use a particle size distribution consisting of a set of \\(P\\) discrete particle/sediment size classes \\(p = 1, 2, ..., P\\). Each size class is represented by a sediment concentration \\(c_p\\) and the mass \\(M_p\\) of the layer deposited by size class \\(p\\) on the bed floor.</p> <p>Each sediment concentration \\(c_p\\) evolves in time according to its own transport equation</p> \\[\\begin{equation} \\frac{\\partial (hc)_p}{\\partial t} + \\nabla\\cdot(h c_p \\vec{u}) = e_p + e_{rp} + r_p + r_{rp} - d_p \\tag{1}\\label{1} \\end{equation}\\] <p>where</p> <ul> <li>\\(h\\) is the water height, as in the shallow water equations</li> <li>\\(\\vec{u} = (u, v)\\) is the water flow velocity, along with which sediments are carried</li> <li>\\(e_p\\) and \\(e_{rp}\\) are the rainfall-driven detachment and re-detachment rates</li> <li>\\(r_p\\) and \\(r_{rp}\\) are the flow-induced entrainment and re-entrainment rates</li> <li>\\(d_p\\) is a deposition rate, expressed as mass per unit area per unit time</li> </ul> <p>and \\(\\nabla\\cdot\\vec{F} = \\partial F_x/\\partial x + \\partial F_y/\\partial y\\) is the 2D divergence of the spatial vector \\(\\vec{F}\\).</p> <p>The deposited layer mass \\(M_p\\) for each size class accumulates according to an ordinary differential equation involving its deposition, re-detachment, and re-entrainment rates:</p> \\[\\begin{equation} \\frac{\\partial M_p}{\\partial t} = d_p - e_{rp} - r_{rp}\\tag{2}\\label{2} \\end{equation}\\] <p>All size classes deposit their layers to the bed floor, changing the bed elevation according to the ordinary differential equation</p> \\[\\begin{equation} (1-\\beta)\\rho_{s}\\frac{\\partial z}{\\partial t} = \\sum_{p=1}^{P}(d_p - e_p - e_{rp} - r_p - r_{rp})\\tag{3}\\label{3} \\end{equation}\\] <p>where </p> <ul> <li>\\(\\beta\\) is the porosity of the soil in its original state</li> <li>\\(\\rho_s\\) is the density of solid sediment, assumed to be the same for all size classes.</li> </ul>"},{"location":"theory/sediment.html#source-terms","title":"Source terms","text":"<p>[Hairsine and Rose, 1992] specify forms for each of the source terms appearing in the H-R equations above.</p>"},{"location":"theory/sediment.html#rainfall-driven-detachment-and-re-detachment-rates","title":"Rainfall-driven detachment and re-detachment rates","text":"\\[\\begin{eqnarray} e_p &amp;=&amp; F_w (1 - H) f_p a_0 R \\\\ e_{rp} &amp;=&amp; F_w H \\frac{M_p}{M_t} a_d R \\tag{4}\\label{4} \\end{eqnarray}\\] <p>where</p> <ul> <li>\\(f_p\\) is the time-dependent ratio of the fraction of sediment in size class \\(p\\)   to its proportion in the soil's original state (i.e. \\(f_p(0) = 1\\))</li> <li>\\(a_0\\) and \\(a_d\\) are the detachability of uneroded and deposited soil, expressed   in mass per unit volume</li> <li>R is the intensity of rainfall, expressed as the change in water height   per unit time</li> <li>\\(M_t = \\sum M_p\\) is the total sediment mass in the deposited layer,   expressed in mass per unit area</li> <li>\\(F_w\\) is a shield factor that attenuates the detachment and re-detachment   rates under conditions where the water height is more than 3 times the   diameter of a \"typical\" raindrop.</li> <li>\\(H = \\min(M_t/(F_w M_t^*),1)\\) is the proportion of shielding of the deposited   layer, given in mass per unit area; here, \\(M_t^*\\) is calibrated to the mass of   deposited sediment needed to completely shield the soil in its original state.</li> </ul> <p>The shield factor \\(F_w\\) can be computed using a power law relation by [Proffitt et al. 1991]:</p> \\[\\begin{equation} F_{w}= \\begin{cases}   1             \\quad &amp; h \\le h_{0} \\\\   (h_{0}/h)^{b} \\quad &amp; h &gt; h_{0}   \\\\ \\end{cases} \\tag{5}\\label{5} \\end{equation}\\] <p>where \\(h_0\\) is a threshold height (typically \\(0.33 D_R\\), with \\(D_R\\) the mean raindrop size).</p> <p>The exponent \\(b\\) in \\(\\eqref{5}\\) varies depending on the type of soil, and can be obtained with a best fit using experimental data. For example, \\(b\\) is 0.66 for clay and 1.13 for loam.</p>"},{"location":"theory/sediment.html#overland-flow-driven-entrainment-and-re-entrainment-rates","title":"Overland flow-driven entrainment and re-entrainment rates","text":"\\[\\begin{eqnarray} r_p &amp;=&amp; (1-H)f_p}\\frac{F(\\Omega-\\Omega_{cr})}{J} \\\\ r_{rp} &amp;=&amp; H\\frac{M_p}{M_{t}}\\frac{F(\\Omega - \\Omega_{cr})}{(\\rho_{s}-\\rho_{w})gh/\\rho_{s}} \\tag{6}\\label{6} \\end{eqnarray}\\] <p>where</p> <ul> <li>\\(\\Omega = \\rho_{w}gh S_f \\sqrt{u^2+v^2}\\) is the stream power in mass per cubic unit time,   with \\(S_f = n^2 (u^2 + v^2) h^{-4/3}\\)</li> <li>\\(\\Omega_{cr}\\) is the critical stream power, below which neither soil   entrainment or re-entrainment occur</li> <li>\\(F\\) is the effective fraction of excess stream power in entrainment or   re-entrainment, which accounts for thermal energy dissipation</li> <li>\\(J\\) is the specific energy of entrainment in energy per unit mass, which   indicates e.g. the energy required for soil of a given mass to be entrained</li> <li>\\(\\rho_{w}\\) is the density of water.</li> </ul>"},{"location":"theory/sediment.html#size-class-deposition-rate","title":"Size class deposition rate","text":"\\[\\begin{equation} d_p = v_p c_p \\tag{7}\\label{7} \\end{equation}\\] <p>where \\(v_p\\) is the settling velocity of each size class with concentration \\(c_p\\), given as mass per unit volume. This model assumes that</p> <ul> <li>the suspended load in the water column is completely mixed in the vertical direction</li> <li>the infiltration rate does not affect size class settling velocities.</li> </ul>"},{"location":"theory/sediment.html#coupling-the-h-r-equations-with-the-shallow-water-equations","title":"Coupling the H-R equations with the Shallow Water Equations","text":"<p>Equations \\(\\eqref{1}\\) can be coupled with the shallow water equations by augment the solution vector \\(\\mathbf{U}\\) with water-height-weighted sediment size-class concentrations:</p> \\[\\begin{align} \\mathbf{U} =   \\begin{bmatrix}     h      \\\\[.5em]     uh     \\\\[.5em]     vh     \\\\     c_1 h \\\\     \\vdots \\\\     c_P h   \\end{bmatrix}. \\end{align}\\] <p>We also augment the flux vectors \\(\\mathbf{E}\\) and \\(\\mathbf{G}\\) from the shallow water equations with the flux terms for the sediment size class transport equations:</p> \\[\\begin{align} \\mathbf{E} =   \\begin{bmatrix}     u h                       \\\\[.5em]     u^2 h + \\frac{1}{2} g h^2 \\\\[.5em]     u v h                     \\\\     c_1 u h                   \\\\     \\vdots                    \\\\     c_P u h   \\end{bmatrix}, \\end{align}\\] \\[\\begin{align} \\mathbf{G} =   \\begin{bmatrix}     v h                       \\\\[.5em]     u v h                     \\\\[.5em]     v^2 h + \\frac{1}{2} g h^2 \\\\     c_1 v h                   \\\\     \\vdots                    \\\\     c_P v h   \\end{bmatrix}. \\end{align}\\] <p>Additionally, we augment the shallow water equation source vector \\(\\mathbf{S}\\) with the (re)attachment, (re)entrainment, and deposition terms:</p> \\[\\begin{align} \\mathbf{S} =   \\begin{bmatrix}     Q     -g h\\frac{\\partial z}{\\partial x} - C_D u\\sqrt{u^2 + v^2} \\\\[.5em]     -g h\\frac{\\partial z}{\\partial y} - C_D v\\sqrt{u^2 + v^2} \\\\     e_1 + e_{r1} + r_1 + r_{r1} - d_1                                 \\\\     \\vdots                                                          \\\\     e_P + e_{rP} + r_P + r_{rP} - d_P   \\end{bmatrix}. \\end{align}\\] <p>Finally, to represent the deposition of mass on the bed floor, we define a deposited mass vector \\(\\mathbf{M}\\) and a net deposition vector \\(\\mathbf{D}\\):</p> \\[\\begin{align} \\mathbf{M} =   \\begin{bmatrix}     M_1    \\\\[.5em]     \\vdots   \\\\     M_P   \\end{bmatrix}, \\end{align}\\] \\[\\begin{align} \\mathbf{D} =   \\begin{bmatrix}     d_1-e_{r1}-r_{r1} \\\\[.5em]     \\vdots              \\\\     d_P-e_{rI}-r_{rP}   \\end{bmatrix}. \\end{align}\\] <p>With these augmented and additional quantities, we can merge the H-R equations with the shallow water equations:</p> \\[\\begin{eqnarray} \\frac{\\partial \\mathbf{U}}{\\partial t} + \\frac{\\partial \\mathbf{E}}{\\partial x} + \\frac{\\partial \\mathbf{G}}{\\partial y} &amp;=&amp; \\mathbf{S}\\\\ \\frac{\\partial \\mathbf{M}}{\\partial t} &amp;=&amp; \\mathbf{D} \\tag{8}\\label{8} \\end{eqnarray}\\] <p>As in the case of the shallow water equations by themselves, we can form a multicomponent spatial flux vector \\(\\mathbf{\\vec{F}} = (\\mathbf{E}, \\mathbf{G})\\) to better accommodate our numerical treatment.</p>"},{"location":"theory/sediment.html#telemacgaia-source-terms","title":"TELEMAC/GAIA source terms","text":"<p>The TELEMAC/GAIA sediment transport model solves the coupled H-R/shallow water equations, but uses simplified source terms in the size-class specific transport equations:</p> \\[\\begin{equation} \\frac{\\partial (h c_p)}{\\partial t} + \\nabla\\cdot\\left(h c_p \\vec{u}\\right) = E_p - D_p \\tag{9} \\label{9} \\end{equation}\\] <p>with source terms \\(E_p\\) and \\(D_p\\) representing size-class-specific erosion and deposition rates, each expressed as mass per unit area per unit time.</p> <p>The GAIA model calculates these erosion and deposition rates from the following expressions for each size class \\(p\\):</p> \\[\\begin{eqnarray} E_p &amp;=&amp; \\mathcal{M} \\left( \\frac{\\tau_b - \\tau_{ce}}{\\tau_{ce}} \\right) \\\\ D_p &amp;=&amp; w_p c_p \\left[ 1 - \\left( \\frac{\\tau_b}{\\tau_{cd}} \\right) \\right] \\tag{10} \\label{10} \\end{eqnarray}\\] <p>where</p> <ul> <li>\\(\\mathcal{M}\\) is the Krone-Partheniades erosion law constant, sometimes called   the \"erodibility coefficient\"</li> <li>\\(w_p\\) is the settling velocity for sediment class \\(p\\)</li> <li>\\(\\tau_{ce}\\) is the critical shear stress for erosion</li> <li>\\(\\tau_{cd}\\) is the critical shear stress for deposition, and</li> <li>\\(\\tau_b = \\rho_s C_D u \\sqrt{u^2 + v^2}\\) is the bed bottom shear stress.</li> </ul>"},{"location":"theory/sediment.html#spatial-discretization","title":"Spatial discretization","text":"<p>The spatial discretization for the coupled H-R/shallow water equations is very similar to the treatment described for the shallow water equations, but uses the augmented solution vector \\(\\mathbf{U}\\), flux \\(\\mathbf{\\vec{F}}\\), and source term \\(\\mathbf{S}\\), which have analogous eigenvectors that can be used to solve the Riemann problem with the Roe method.</p> <p>Defining quantities normal to the face separating two cells (or on the boundary) with a \\(\\parallel\\) subscript and the angle \\(\\phi\\) separating the face normal from the \\(x\\) axis, the normal flux is</p> \\[\\begin{align} \\mathbf{\\vec{F}} \\cdot \\vec{n} =   \\begin{bmatrix}     hu_{\\parallel}                                                                  \\\\[.5em]     huu_{\\parallel} + \\frac{1}{2}gh^{2}cos \\phi + \\frac{1}{24}g\\Delta h^{2}cos \\phi \\\\     hvu_{\\parallel} + \\frac{1}{2}gh^{2}sin \\phi + \\frac{1}{24}g\\Delta h^{2}sin \\phi \\\\     hc_1 u_{\\parallel}                                                             \\\\     \\vdots                                                                          \\\\     hc_P u_{\\parallel}                                                             \\\\   \\end{bmatrix}\\tag{11}\\label{11}. \\end{align}\\] <p>The last terms in the second and third rows of \\(\\eqref{11}\\) are hydrostatic thrust correction terms suggested by Bradford and Sanders [2002]. These terms balance the bed slope terms for the still water condition.</p> <p>The fluxes at the interface between cells can be approximated with Roe's method:</p> \\[\\begin{equation} \\mathbf{F} \\cdot \\mathbf{n} \\approx \\mathbf{F}_{\\parallel,f} = \\frac{1}{2} \\left(\\mathbf{F}_{\\parallel,L} + \\mathbf{F}_{\\parallel,R}-\\mathbf{\\hat{R}} |\\mathbf{\\hat{\\Lambda}}| \\mathbf{\\Delta\\hat{V}} \\right) \\end{equation}\\] <p>where the subscript \\(f\\) annotates the interface between two adjacent cells, \\(L\\) and \\(R\\) indicate the \"left\" and \"right\" states for the interface, and \\(\\Delta\\) denotes the difference in quantities across the interface. The terms \\(\\mathbf{\\hat{R}}\\) and \\(\\mathbf{\\hat{\\Lambda}}\\) are the right eigenvector and the eigenvalue of the Jacobian of \\(\\mathbf{F}_{\\parallel}\\), and \\(\\mathbf{\\Delta}\\mathbf{\\hat{V}}=\\hat{L}\\Delta U\\) denotes the wave strength, with \\(\\hat{L}\\) the left eigenvector of the Jacobian of \\(\\mathbf{F}_{\\parallel}\\).</p> \\[\\begin{align} \\mathbf{\\hat{R}} =   \\begin{bmatrix}     1                         &amp; 0           &amp; 1                         &amp; 0      &amp; \\ldots &amp; 0      \\\\     \\hat{u}-\\hat{a}cos \\theta &amp; -sin \\theta &amp; \\hat{u}+\\hat{a}cos \\theta &amp; 0      &amp; \\ldots &amp; 0      \\\\     \\hat{v}-\\hat{a}sin \\theta &amp;  cos \\theta &amp; \\hat{v}+\\hat{a}sin \\theta &amp; 0      &amp; \\ldots &amp; 0      \\\\     \\hat{c_1}               &amp; 0           &amp; \\hat{c_1}               &amp; 1      &amp; \\ldots &amp; 0      \\\\     \\vdots                    &amp; \\vdots      &amp; \\vdots                    &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\      \\hat{c_P}               &amp; 0           &amp; \\hat{c_P}               &amp; 0      &amp; \\ldots &amp; 1      \\\\   \\end{bmatrix} \\end{align}\\] \\[\\begin{align} \\mathbf{\\hat{\\Lambda}} =   \\begin{bmatrix}     |\\hat{u_{\\parallel}}-\\hat{a}|^{*} &amp;                   &amp;                               &amp;                   &amp;        &amp;                   \\\\                                   &amp; |\\hat{u_{\\parallel}}| &amp;                               &amp;                   &amp;        &amp;                   \\\\                                   &amp;                   &amp; |\\hat{u_{\\parallel}}+\\hat{a}|^{*} &amp;                   &amp;        &amp;                   \\\\                                   &amp;                   &amp;                               &amp; |\\hat{u_{\\parallel}}| &amp;        &amp;                   \\\\                                   &amp;                   &amp;                               &amp;                   &amp; \\ddots &amp;                   \\\\                                   &amp;                   &amp;                               &amp;                   &amp;        &amp; |\\hat{u_{\\parallel}}| \\\\   \\end{bmatrix} \\end{align}\\] \\[\\begin{align} \\mathbf{\\Delta}\\mathbf{\\hat{V}}=\\hat{L}\\Delta U =   \\begin{bmatrix}     \\frac{1}{2} \\left( \\Delta h - \\frac{\\hat{h}\\Delta u_\\perp}{\\hat{a}} \\right) \\\\[.5em]     \\hat{h}u_\\perp                                                          \\\\[.5em]     \\frac{1}{2} \\left( \\Delta h + \\frac{\\hat{h}\\Delta u_\\perp}{\\hat{a}} \\right) \\\\[.5em]     (c_1 h)_{R} - (c_1 h)_{L} - \\hat{c_1}(h_{R}-h_{L})                      \\\\[.5em]     \\vdots                                                                      \\\\[.5em]     (c_P h)_{R} - (c_P h)_{L} - \\hat{c_P}(h_{R}-h_{L})                      \\\\[.5em]   \\end{bmatrix} \\end{align}\\] <p>Above,</p> <ul> <li>\\(a\\) is the celerity of a simple gravity wave, and</li> <li>\\(u_{\\perp} = -u \\sin \\phi + v \\cos \\phi\\) is the velocity perpendicular to   the interface normal.</li> </ul> <p>The quantities with a hat are Roe averages, which are calculated thus:</p> \\[\\begin{eqnarray} \\hat{h}   &amp;=&amp; \\sqrt{h_L h_R}                                              \\\\ \\hat{u}   &amp;=&amp; \\frac{\\sqrt{h_L}u_L + \\sqrt{h_R}u_R}{\\sqrt{h_L}+\\sqrt{h_R}} \\\\ \\hat{v}   &amp;=&amp; \\frac{\\sqrt{h_L}v_L + \\sqrt{h_R}v_R}{\\sqrt{h_L}+\\sqrt{h_R}} \\\\ \\hat{a}   &amp;=&amp; \\sqrt{\\frac{g}{2}(h_L + h_R)}                               \\\\ \\hat{c_i} &amp;=&amp; \\frac{\\sqrt{h_L}c_{i,L}+\\sqrt{h_R} c_{i,R}}{\\sqrt{h_L}+\\sqrt{h_R}} \\end{eqnarray}\\] <p>The asterisks indicate that the eigenvalues \\(\\hat{\\lambda}_1=\\hat{u}_{\\parallel}-\\hat{a}\\) and \\(\\hat{\\lambda}_{3}=\\hat{u}_{\\parallel}+\\hat{a}\\) are adjusted because Roe's method does not provide correct fluxes for critical flow:</p> \\[\\begin{equation} |\\hat{\\lambda}_1|^{*} = \\frac{\\hat{\\lambda}_1^{2}}{\\Delta \\lambda} + \\frac{\\Delta \\lambda}{4} \\quad if \\quad -\\Delta \\lambda /2 &lt; \\hat{\\lambda}_1 &lt; \\Delta \\lambda /2 \\end{equation}\\] \\[\\begin{equation} |\\hat{\\lambda}_{3}|^{*} = \\frac{\\hat{\\lambda}_{3}^{2}}{\\Delta \\lambda} + \\frac{\\Delta \\lambda}{4} \\quad if \\quad -\\Delta \\lambda /2 &lt; \\hat{\\lambda}_{3} &lt; \\Delta \\lambda /2 \\end{equation}\\] <p>with \\(\\Delta \\lambda = 4(\\lambda_{R}-\\lambda_{L})\\).</p>"},{"location":"theory/sediment.html#references","title":"References","text":"<ul> <li>Hairsine, P. B., and C. W. Rose (1991). Rainfall detachment and deposition: Sediment transport in the absence of flow-driven processes, Soil Sci. Soc. Am. J., 55(2), 320\u2013324.</li> <li>Hairsine, P. B., and C. W. Rose (1992). Modeling water erosion due to overland flow using physical principles: 1. Sheet flow, Water Resour. Res., 28(1), 237\u2013243.</li> <li>Kim, J., V. Y. Ivanov, and N. D. Katopodes (2013). Modeling erosion and sedimentation coupled with hydrological and overland flow processes at the watershed scale, Water Resour. Res., 49, 5134\u20135154, doi:10.1002/wrcr.20373.</li> </ul>"},{"location":"theory/swe.html","title":"Shallow Water Equations","text":"<p>The two-dimensional shallow water equations can be written in the conservative form</p> \\[ \\frac{\\partial\\mathbf{U}}{\\partial t} + \\frac{\\partial \\mathbf{E}}{\\partial x} + \\frac{\\partial \\mathbf{G}}{\\partial y} = \\mathbf{S}_r + \\mathbf{S}_b + \\mathbf{S}_f \\tag{1}\\label{1} \\] <p>Here,</p> \\[\\begin{align}   \\mathbf{U}   =   \\begin{bmatrix}   h \\\\[.5em]   hu \\\\[.5em]   hv   \\end{bmatrix}, \\end{align}\\] <p>is the solution vector, with components</p> <ul> <li>\\(h\\), the flow depth</li> <li>\\(u\\), the vertically-averaged velocity in the \\(x\\) direction</li> <li>\\(v\\), the vertically-averaged velocity in the \\(y\\) direction</li> </ul> <p>The terms \\(\\mathbf{E}\\) and \\(\\mathbf{G}\\) on the left hand side of \\(\\eqref{1}\\) are the flux vectors in the \\(x\\) and \\(y\\) spatial dimensions:</p> \\[\\begin{align}   \\mathbf{E}   =   \\begin{bmatrix}   hu \\\\[.5em]   hu^2 + \\frac{1}{2}gh^2 \\\\[.5em]   huv   \\end{bmatrix}, \\end{align}\\] \\[\\begin{align}   \\mathbf{G}   =   \\begin{bmatrix}   hv \\\\[.5em]   huv \\\\[.5em]   hv^2 + \\frac{1}{2}gh^2   \\end{bmatrix}, \\end{align}\\] <p>where \\(g\\) is the acceleration due to gravity.</p> <p>The three source terms on the right hand side of \\(\\eqref{1}\\) represent contributions to \\(\\mathbf{U}\\) from</p> <ul> <li>\\(\\mathbf{S}_r\\), net runoff (water) production</li> <li>\\(\\mathbf{S}_b\\), bed elevation slope</li> <li>\\(\\mathbf{S}_f\\), bed friction roughness.</li> </ul> <p>These source terms are</p> \\[\\begin{align}   \\mathbf{S}_r   =   \\begin{bmatrix}   Q \\\\[.5em]   0 \\\\[.5em]   0   \\end{bmatrix}, \\end{align}\\] \\[\\begin{align}   \\mathbf{S}_b   =   \\begin{bmatrix}   0 \\\\[.5em]   -gh\\frac{\\partial z}{\\partial x} \\\\[.5em]   -gh\\frac{\\partial z}{\\partial y}   \\end{bmatrix}, \\end{align}\\] <p>and</p> \\[\\begin{align}   \\mathbf{S}_f   =   \\begin{bmatrix}   0 \\\\[.5em]   - C_D u \\sqrt{u^2 + v^2} \\\\[.5em]   - C_D v \\sqrt{u^2 + v^2}   \\end{bmatrix}. \\end{align}\\] <p>It is sometimes convenient to interpret the terms involving \\(\\mathbf{E}\\) and \\(\\mathbf{G}\\) as the (two-dimensional) divergence of a multi-component spatial vector called the flux function \\(\\mathbf{\\vec{F}}\\).</p> \\[ \\frac{\\partial\\mathbf{U}}{\\partial t} + \\vec{\\nabla}\\cdot\\mathbf{\\vec{F}}(\\mathbf{U}) = \\mathbf{S}(\\mathbf{U})\\tag{2}\\label{2} \\] <p>where \\(\\mathbf{\\vec{F}} = (\\mathbf{F}_x, \\mathbf{F}_y) = (\\mathbf{E}, \\mathbf{G})\\).</p> <p>We have written \\(\\mathbf{\\vec{F}}\\) and \\(\\mathbf{S}\\) in \\(\\eqref{2}\\) in a way that emphasizes that these functions depend on the solution vector \\(\\mathbf{U}\\).</p>"},{"location":"theory/swe.html#spatial-discretization","title":"Spatial Discretization","text":"<p>We can rewrite the shallow water equations in a form more convenient for numerical treatment by defining a computational domain \\(\\Omega\\) bounded by a piecewise linear closed curve \\(\\Gamma = \\partial\\Omega\\).</p> <p>We create a discrete representation by partitioning \\(\\Omega\\) into disjoint cells, with \\(\\Omega_i\\) representing cell \\(i\\). The boundary of cell \\(i\\), written \\(\\partial\\Omega_i\\), is the set of faces separating it from its neighboring cells. Using this notation, we obtain a discrete set of equations for the solution in cell \\(i\\) by integrating \\(\\eqref{1}\\) over \\(\\Omega_i\\) and using Green's theorem:</p> \\[\\begin{eqnarray} \\frac{\\partial}{\\partial t} \\int_{\\Omega_i} \\mathbf{U} d\\Omega_i + \\int_{\\Omega_i} \\left[ \\frac{\\partial\\mathbf{E}}{\\partial x} + \\frac{\\partial\\mathbf{G}}{\\partial y} \\right] d\\Omega_i &amp;=&amp; \\int_{\\Omega_i} \\mathbf{S} d\\Omega_i \\nonumber\\\\ \\frac{\\partial}{\\partial t} \\int_{\\Omega_i} \\mathbf{U} d\\Omega_i + \\oint_{\\partial\\Omega_i} \\left( \\mathbf{E}~dy - \\mathbf{G}~dx \\right) &amp;=&amp; \\int_{\\Omega_i} \\mathbf{S} d\\Omega_i \\tag{3}\\label{3} \\end{eqnarray}\\] <p>This equation can be used to approximate discontinuous flows, because all quantities appear under integrals. By contrast, \\(\\eqref{1}\\) cannot be used where derivatives of \\(\\mathbf{U}\\) don't exist.</p> <p>We can interpret the line integral in \\(\\eqref{3}\\) in terms of the flux \\(\\mathbf{\\vec{F}} = (\\mathbf{F}_x, \\mathbf{F}_y)\\) between a cell \\(i\\) and its neighboring cells.</p> \\[  \\frac{\\partial}{\\partial t} \\int_{\\Omega_i} \\mathbf{U} d\\Omega_i + \\oint_{\\partial\\Omega_i} \\mathbf{\\vec{F}} \\cdot \\vec{n}~dl = \\int_{\\Omega_i} \\mathbf{S} d\\Omega_i \\tag{4}\\label{4} \\] <p>Here, we have defined a unit normal vector \\(\\vec{n} = (n_x, n_y)\\) pointing outward along the cell boundary \\(\\partial\\Omega_i\\). \\(\\eqref{4}\\) is a \"surface integral\" with a differential arc length \\(dl\\) integrated over the boundary of cell \\(i\\). One obtains this surface integral by integrating \\(\\eqref{2}\\) over the domain \\(\\Omega\\) and applying the (two-dimensional) divergence theorem to the flux term.</p> <p>In the rest of this section, we use the flux form \\(\\eqref{4}\\) of the shallow water equations.</p> <p>We can obtain a finite volume method for these equations by defining horizontally-averaged quantities for flow depth and velocities:</p> \\[\\begin{eqnarray} h_i &amp;=&amp; \\frac{1}{A_i}\\int_{\\Omega_i} h d\\Omega_i \\\\ u_i &amp;=&amp; \\frac{1}{A_i}\\int_{\\Omega_i} u d\\Omega_i \\\\ v_i &amp;=&amp; \\frac{1}{A_i}\\int_{\\Omega_i} v d\\Omega_i \\end{eqnarray}\\] <p>where \\(A_i = \\int_{\\Omega_i}d\\Omega_i\\) is the area enclosed within cell \\(i\\). We also introduce the horizontally-averaged solution vector</p> \\[ \\mathbf{U}_i = [h_i, h_i u_i, h_i v_i]^T \\] <p>and the horizontally-averaged source vector</p> \\[ \\mathbf{S}_i = \\frac{1}{A_i}\\int_{\\Omega_i} \\left(\\mathbf{S}_r + \\mathbf{S}_b + \\mathbf{S}_f\\right) d\\Omega_i. \\] <p>Finally, we define the face-averaged normal flux vector between cell \\(i\\) and an adjoining cell \\(j\\):</p> \\[ \\mathbf{F}_{ij} = \\frac{1}{l_{ij}}\\int_{\\partial\\Omega_i\\bigcap\\partial\\Omega_j}\\mathbf{\\vec{F}}\\cdot\\vec{n}~dl \\tag{5}\\label{5} \\] <p>where \\(l_{ij}\\) is the length of the face connecting cells \\(i\\) and \\(j\\).</p> <p>With these definitions, the shallow water equations in cell \\(i\\) are</p> \\[ \\frac{\\partial\\mathbf{U}_i}{\\partial t} + \\sum_j\\mathbf{F}_{ij} l_{ij} = \\mathbf{S}_i, \\tag{6}\\label{6} \\] <p>where the index \\(j\\) in each term of the sum refers to a neighboring cell of cell \\(i\\).</p>"},{"location":"theory/swe.html#boundary-conditions","title":"Boundary conditions","text":"<p>To incorporate boundary conditions, we partition the domain boundary \\(\\Gamma\\) into disjoint line segments, each of which represents a boundary face \\(\\Gamma_i\\). Every cell \\(j\\) that touches the boundary \\(\\Gamma\\) has at least one boundary face. Such a cell is a boundary cell. The boundary \\(\\Gamma\\) consists entirely of faces of boundary cells.</p> <p>In dealing with boundary conditions, we must distinguish between the faces a boundary cell \\(i\\) does and does not share with the boundary \\(\\Gamma\\):</p> \\[\\begin{eqnarray} \\frac{\\partial\\mathbf{U}_i}{\\partial t} + \\sum_{j: \\partial\\Omega_j\\subset\\Gamma}\\mathbf{F}_{ij}^{\\Gamma} l_{ij} &amp;+&amp; \\sum_{j: \\partial\\Omega_j\\not\\subset\\Gamma}\\mathbf{F}_{ij} l_{ij} &amp;= \\mathbf{S}_i. \\tag{7}\\label{7} \\\\ \\text{(boundary)}&amp; &amp;\\text{(interior)} &amp; \\end{eqnarray}\\] <p>To enforce boundary conditions, we must compute the effective boundary fluxes \\(\\mathbf{F}_{ij}^{\\Gamma}\\) that appear in the first sum in \\(\\eqref{7}\\). These boundary fluxes have specific forms depending on their respective boundary conditions.</p>"},{"location":"theory/swe.html#evaluating-normal-fluxes","title":"Evaluating normal fluxes","text":"<p>We have reduced the spatial discretization of our finite volume method to the calculation of normal fluxes between neighboring cells and on boundary faces. The normal flux function is</p> \\[\\begin{equation} \\mathbf{\\vec{F}}\\cdot\\vec{n} = \\mathbf{E} n_x + \\mathbf{G} n_y. \\end{equation}\\] <p>We can evaluate \\(\\mathbf{F}_{ij} \\approx \\mathbf{\\vec{F}}\\cdot\\vec{n}\\), the approximate normal flux at a face shared shared by interior cells \\(i\\) and \\(j\\), by solving the relevant Riemann problem using Roe's method. If we designate \\(\\phi\\) as the angle between \\(\\vec{n}\\) and the \\(x\\) axis and adopt \\(i\\) and \\(j\\) subscripts for quantities respectively in cells \\(i\\) and \\(j\\), we can approximate the normal flux by the expression</p> \\[\\begin{equation} \\mathbf{F}_{ij} = \\frac{1}{2} \\left( \\mathbf{\\vec{F}}_i + \\mathbf{\\vec{F}}_j - \\mathbf{\\hat{R}} |\\mathbf{\\hat{\\Lambda}| \\mathbf{\\Delta}\\hat{V}} \\right) \\end{equation}\\] <p>where \\(\\Delta f\\) is the variation of the quantity of \\(f\\) along a face. In particular,</p> \\[\\begin{align}   \\mathbf{R}   =   \\begin{bmatrix}   1 &amp; 0 &amp; 1  \\\\[.5em]   \\hat{u} - \\hat{a}\\cos\\phi &amp; -\\sin\\phi &amp; \\hat{u} + \\hat{a}\\cos\\phi  \\\\[.5em]   \\hat{v} - \\hat{a}\\sin\\phi &amp;  \\cos\\phi &amp; \\hat{v} + \\hat{a}\\sin\\phi   \\end{bmatrix} \\end{align}\\] \\[\\begin{align}   \\mathbf{\\Delta\\hat{V}}   =   \\begin{bmatrix}   \\frac{1}{2} \\left( \\Delta h - \\frac{\\hat{h}\\Delta u_\\parallel}{\\hat{a}} \\right) \\\\[.5em]   \\hat{h}u_\\perp \\\\[.5em]   \\frac{1}{2} \\left( \\Delta h + \\frac{\\hat{h}\\Delta u_\\parallel}{\\hat{a}} \\right)   \\end{bmatrix} \\end{align}\\] \\[\\begin{align}   |\\mathbf{\\hat{\\Lambda}}|   =   \\begin{bmatrix}   | \\hat{u}_\\parallel - \\hat{a} |^* &amp; 0 &amp; 0  \\\\[.5em]   0                                 &amp; |\\hat{u}_\\parallel| &amp; 0 \\\\[.5em]     0                                 &amp;                     &amp; | \\hat{u}_\\parallel + \\hat{a} |^*    \\end{bmatrix} \\end{align}\\] <p>where</p> \\[\\begin{eqnarray}   \\hat{h} &amp; = &amp; \\sqrt{h_i h_j} \\\\   \\hat{u} &amp; = &amp; \\frac{ \\sqrt{h_i} \\vec{u}_i + \\sqrt{h_j} \\vec{u}_j}{ \\sqrt{h_i} + \\sqrt{h_j}} \\\\   \\hat{v} &amp; = &amp; \\frac{ \\sqrt{h_i} \\vec{v}_i + \\sqrt{h_j} \\vec{v}_j}{ \\sqrt{h_i} + \\sqrt{h_j}} \\\\   \\hat{a} &amp; = &amp; \\sqrt{\\frac{g}{2} \\left( h_i + h_j \\right)}, \\end{eqnarray}\\] <p>\\(\\Delta f = f_j - f_i\\) is the change in the quantity \\(f\\) moving from cell \\(i\\) to \\(j\\), and \\(w_\\parallel = \\vec{w}\\cdot\\vec{n}\\) and \\(w_\\perp = |\\vec{w} - w_\\parallel \\vec{n}|\\) for any vector \\(\\vec{w}\\).</p> <p>We have used asterisks in the expression for \\(|\\mathbf{\\hat{\\Lambda}}|\\) to indicate that the eigenvalues  \\(\\hat{\\lambda}_1 = \\hat{u}_\\perp - \\hat{a}\\) and \\(\\hat{\\lambda}_3 = \\hat{u}_\\perp + \\hat{a}\\)  must be adjusted, since Roe's method does not provide the correct flux for critical flow.</p> \\[\\begin{eqnarray}   |\\hat{\\lambda}|_1 &amp;=&amp; \\frac{\\hat{\\lambda}^2_1}{\\Delta \\lambda} + \\frac{\\Delta \\lambda}{4} \\mbox{$~$ if $~ -\\Delta \\lambda/2 &lt; \\hat{\\lambda}_1 &lt; \\Delta \\lambda/2$} \\\\   |\\hat{\\lambda}|_3 &amp;=&amp; \\frac{\\hat{\\lambda}^2_2}{\\Delta \\lambda} + \\frac{\\Delta \\lambda}{4} \\mbox{$~$ if $~ -\\Delta \\lambda/2 &lt; \\hat{\\lambda}_3 &lt; \\Delta \\lambda/2$} \\end{eqnarray}\\]"},{"location":"theory/swe.html#source-terms","title":"Source terms","text":"<p>Recall that there are three source terms \\(\\mathbf{S}_r\\), \\(\\mathbf{S}_b\\), and \\(\\mathbf{S}_f\\). In this section, we write the source terms for the momentum vector as \\(\\mathbf{S}_b = [0, \\mathbf{\\vec{S}}_b]^T\\) and \\(\\mathbf{S}_f = [0, \\mathbf{\\vec{S}}_f]^T\\) because their second and third components correspond to the spatial components of the momentum vector.</p>"},{"location":"theory/swe.html#net-runoff-production-mathbfs_r","title":"Net runoff production \\(\\mathbf{S}_r\\)","text":"<p>This source term contributes only to height of the water, and is expressed as \\(\\mathbf{S}_r = [Q_r, 0, 0]^T\\), where \\(Q_r\\), the net runoff production, with units of water height per unit time, is</p> <ul> <li>a constant</li> <li>a spatially homogeneous time-dependent function \\(Q_r(t)\\), or</li> <li>a spatially heterogeneous time-dependent function \\(Q_r(x, y, t)\\).</li> </ul> <p>In any case, we can approximate the integral of this term using the mean value theorem of calculus:</p> \\[\\begin{equation} \\int_{\\Omega_i} S_r~d\\Omega_i = \\int_{\\Omega_i} [Q_r, 0, 0]^T~d\\Omega \\approx [Q_r A_i, 0, 0]^T, \\end{equation}\\] <p>where \\(A_i\\) is the area of cell \\(i\\).</p>"},{"location":"theory/swe.html#bed-elevation-slope-term-mathbfs_b","title":"Bed elevation slope term \\(\\mathbf{S}_b\\)","text":"<p>This term represents the force of gravity on the water and can be approximated as</p> \\[\\begin{equation} \\int_{\\Omega_i} \\mathbf{\\vec{S}}_b~d\\Omega_i = \\int_{\\Omega_i} -gh\\nabla z~d\\Omega_i \\approx -gh\\left(\\overline{\\frac{\\partial z}{\\partial x}}, \\overline{\\frac{\\partial z}{\\partial y}}\\right) A_i \\end{equation}\\] <p>where \\(\\nabla z = (\\partial z/\\partial x, \\partial z/\\partial y)\\) is the two-dimensional gradient of the bed elevation function \\(z\\).</p> <p>For a triangular grid cell,</p> \\[\\begin{eqnarray} \\overline{\\frac{\\partial z}{\\partial x}} &amp;=&amp; \\frac{(y_2 - y_0)(z_1 - z_0) - (y_1 - y_0)(z_2 - z_0)}{(y_2 - y_0)(x_1 - x_0) - (y_1 - y_0)(x_2 - x_0)} \\\\ \\overline{\\frac{\\partial z}{\\partial y}} &amp;=&amp; \\frac{(x_2 - x_0)(z_1 - z_0) - (x_1 - x_0)(z_2 - z_0)}{(x_2 - y_0)(x_1 - x_0) - (x_1 - y_0)(y_2 - y_0)}. \\end{eqnarray}\\]"},{"location":"theory/swe.html#bed-friction-roughness-term-mathbfs_f","title":"Bed friction roughness term \\(\\mathbf{S}_f\\)","text":"<p>Like the runoff term, this term involves only quantities within a single cell and can be approximated by the mean value theorem:</p> \\[\\begin{equation} \\int_{\\Omega_i} \\mathbf{\\vec{S}}_f~d\\Omega_i = \\int_{\\Omega_i} C_D \\vec{u} \\sqrt{u^2 + v^2}~d\\Omega_i \\approx C_D \\vec{u}_i \\sqrt{u_i^2 + v_i^2} A_i \\end{equation}\\] <p>where \\(C_D = g n_i^2 h_i^{-1/3}\\) and \\(\\vec{u}_i = (u, v)\\) are, respectively, the drag coefficient and the flow velocity vector in cell \\(i\\). The \\(x\\) and \\(y\\) spatial components of \\(\\mathbf{\\vec{S}}_f\\) contribute to the second and third components of the source term.</p>"},{"location":"theory/swe.html#temporal-discretization","title":"Temporal Discretization","text":"<p>The above spatial discretization produces a \"semi-discrete\" system of equations that can be integrated using various methods for solving systems of ordinary differential equations. The following methods of integration are provided by PETSc and supported for RDycore:</p> <ul> <li>Forward Euler</li> </ul>"},{"location":"theory/swe.html#references","title":"References","text":"<ul> <li> <p>Bradford, S. F., &amp; Sanders, B. F. (2002). Finite-volume model for shallow-water flooding of arbitrary topography. Journal of hydraulic engineering, 128(3), 289-298.</p> </li> <li> <p>Kim, J., Warnock, A., Ivanov, V. Y., &amp; Katopodes, N. D. (2012). Coupled modeling of hydrologic and hydrodynamic processes including overland and channel flow. Advances in water resources, 37, 104-126.</p> </li> </ul>"},{"location":"user/index.html","title":"RDycore User Guide - Overview","text":"<p>RDycore's primary purpose is to provide E3SM with the capability to model coastal compound flooding. Accordingly, it has been constructed as a performance-portable library that makes efficient use of DOE's leadership-class computing facilities and is invoked by E3SM Fortran code.</p> <p>Aside from the library, RDycore provides standalone drivers that can help you test and evaluate the model's capabilities:</p> <ul> <li> <p>standalone C and Fortran driver programs for running uncoupled flood   simulations given appropriate initial and boundary conditions, source terms,   etc.</p> </li> <li> <p>standalone C and Fortran verification programs that use the method of   manufactured solutions (MMS) to evaluate the stability and accuracy of the   underlying numerical methods by computing error norms of simulation results   measured against analytical solutions. These MMS programs can also compute   convergence rates, which are useful for identifying algorithmic and   programming errors. Because these programs are more technical and used to   identify defects, they are described in the Developer Guide.</p> </li> </ul> <p>This guide also describes these standalone programs and their features. It also explains how we integrate RDycore to E3SM to perform coupled simulations of compound flooding.</p>"},{"location":"user/index.html#the-standalone-c-and-fortran-drivers","title":"The Standalone C and Fortran Drivers","text":"<ul> <li>Standalone YAML input specification</li> </ul>"},{"location":"user/example-cases/example-cases.html","title":"Running Examples on Supported DOE Machines","text":"<p>Here we provide a few examples cases for running RDycore on DOE's supercomputers. Each case directory contains the following:</p> <ul> <li><code>index.md</code> that describes the case</li> <li>RDycore input YAML file for the case</li> <li>Placeholder batch scripts for the DOE supercomputers on which the case has been previously run</li> <li>A bash script that:<ul> <li>Compiles RDycore, if needed, and</li> <li>Generates a batch script that must submitted via <code>sbatch</code></li> </ul> </li> </ul> <p>The files for the meshes, boundary conditions, and source-sink terms are not included in the repository and are instead available in RDycore shared project directory on the supported DOE's supercomputers.</p> <p>The following cases are supported:</p> <ol> <li>Idealized dam break problem</li> <li>Flooding of Houston during Hurricane Harvey</li> </ol>"},{"location":"user/example-cases/dam-break/index.html","title":"Overview","text":"<p>This is an idealized partial dam break case with an initial water height of 10 m and 5 m to the left and right of the dam, respcitively, as shown below. The initial velocities in x- and y-direction are zero within the domain.</p> <p></p> <p>The input YAML file (<code>inputdeck_5120x2560.yaml</code>) corresponds to a mesh with <code>dx = dy = 0.002</code> m and has 11,534,336 grid cells. Reflective boundary condition is assumed for all boundaries of the mesh. The problem is setup to take 100 timesteps. The mesh is in DMPlex's HDF5 v3.0.0 format. It is assumed that the user has access the RDycore's project directories on the DOE supercomputers, which contains the mesh and pre-installed PETSc. The supported DOE supercomputers for this case are:</p> <ol> <li>Perlmutter (CPU-nodes and GPU-nodes)</li> <li>Frontier</li> </ol> <p>The project directories on these supported machines additionally contain  meshes for the idealized dam break problem at few additional resolutions:</p> <ol> <li><code>DamBreak_grid2560x1280.v3.0.0.h5</code>: 2,883,584 grid cells</li> <li><code>DamBreak_grid10240x5120.v3.0.0.h5</code>: 46,137,344 grid cells</li> <li><code>DamBreak_grid20480x10240.v3.0.0.h5</code>: 184,549,376 grid cells</li> </ol>"},{"location":"user/example-cases/dam-break/index.html#script","title":"Script","text":"<p><code>setup_batch_for_dam_break.sh</code> Will create symbolic link to the mesh file locally, compile RDycore (if needed), and create a batch script for DOE supercomputers that can be submitted via <code>sbatch</code>. </p> <pre><code> ./setup_batch_for_dam_break.sh -h\nUsage: ./setup_batch_for_dam_break.sh\n\n   -h, --help                        Display this message\n   --rdycore-dir                     Path to RDycore directory\n   --mach &lt;pm-cpu|pm-gpu|frontier&gt;   Supported machine name\n   --frontier-node-type &lt;cpu|gpu&gt;    To run on Frontier CPUs or GPUs\n   -N --node  &lt;N&gt;                    Number of nodes (default = 1)\n   --project &lt;project-id&gt;            Project ID that will charged for the job\n</code></pre> <ul> <li>For Perlmutter:</li> <li><code>--mach pm-cpu</code> Run RDycore on CPU nodes</li> <li><code>--mach pm-gpu</code> Run RDycore GPU nodes using CUDA</li> <li>For Frontier (<code>--mach frontier</code>):</li> <li><code>--frontier-node-type cpu</code>: Run RDycore on CPUs</li> <li><code>--frontier-node-type gpu</code>: Run RDycore on GPUs using HIP</li> </ul>"},{"location":"user/example-cases/dam-break/index.html#example-for-perlmutter-cpu-nodes","title":"Example for Perlmutter CPU nodes","text":"<pre><code>./setup_batch_for_dam_break.sh --mach pm-cpu --project m4267 -N 2 \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore\n</code></pre>"},{"location":"user/example-cases/dam-break/index.html#example-for-perlmutter-gpu-nodes","title":"Example for Perlmutter GPU nodes","text":"<pre><code>./setup_batch_for_dam_break.sh --mach pm-gpu --project m4267_g -N 1 \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore\n</code></pre>"},{"location":"user/example-cases/dam-break/index.html#example-for-frontier-using-cpus","title":"Example for Frontier using CPUs","text":"<pre><code>./setup_batch_for_dam_break.sh --mach frontier --frontier-node-type cpu -N 1 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"},{"location":"user/example-cases/dam-break/index.html#example-for-frontier-using-gpus","title":"Example for Frontier using GPUs","text":"<pre><code>./setup_batch_for_dam_break.sh --mach frontier --frontier-node-type gpu -N 1 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"},{"location":"user/example-cases/e3sm-cases/index.html","title":"E3SM-RDycore","text":"<p>The coupled E3SM-RDycore is developed within a fork of the E3SM repository under the RDycore's Github account at https://github.com/rdycore/e3sm.  The coupled model is developed in a branch within the forked repository and the current branch is named <code>rdycore/mosart-rdycore/d4ca7d0606-2024-10-02</code>.  The <code>d4ca7d0606</code> corresponds to the Git hash of the commit on the E3SM master branch from which the current E3SM-RDycore development branch started and <code>2024-10-02</code> corresponds to the date of that starting commit.</p> <pre><code># From E3SM repo\n&gt;git show d4ca7d0606\ncommit d4ca7d0606930f53f30eb7ff7dbb92ec83b83b84 (tag: v3.0.1, e3sm/next, e3sm/master, e3sm/HEAD, master)\nMerge: f1e03b784b 55f473dcde\nAuthor: Robert Jacob &lt;jacob@anl.gov&gt;\nDate:   Wed Oct 2 16:21:12 2024 -0500\n\n    Merge branch 'rljacob/doc/updateforv301' (PR #6658)\n\n    Update README, CITATION.cff and LICENSE for v3.0.1\n\n    [BFB]\n</code></pre> <p>The E3SM-RDycore development branch is occasionally rebased on E3SM's master. After a rebase, the E3SM-RDycore development branch is named such that the new name correctly represents the starting commit hash and the commit date. The RDycore has been added in E3SM as a submodule at <code>externals/rdycore</code>. In the current model coupling, RDycore is part of the MOSART as shown below.</p> <p></p> <p>The following E3SM-RDycore case is supported: 1. Hurricane Havey flooding</p>"},{"location":"user/example-cases/e3sm-cases/harvey-flooding/e3sm_harvey.html","title":"Overview","text":"<p>The E3SM-RDycore model has been tested on Perlmutter and Frontier for the RDycore's 5-day Hurricane Harvey benchmark. The E3SM-RDycore simulation uses a data-land configuration with an active river model. In an E3SM-RDycore run, RDycore can run on CPUs and GPUs. The overall workflow for an E3SM-RDycore run is as follows:</p> <ul> <li> <p>Get the code:</p> <ul> <li>Clone the E3SM fork from https://github.com/rdycore/e3sm.</li> <li>Switch to the E3SM-RDycore development branch and initialize submodules of E3SM and RDycore. <pre><code>git clone git@github.com:rdycore/e3sm\ncd e3sm\ngit checkout rdycore/mosart-rdycore/d4ca7d0606-2024-10-02\ngit submodule update --init\ncd externals/rdycore\ngit submodule update --init\n</code></pre></li> </ul> </li> <li> <p>Create, build, and run a case</p> <ol> <li>Compile RDycore to generate libraries (i.e. <code>librdycore.a</code>, <code>librdycore_f90.a</code>, <code>libcyaml.a</code>, <code>libyaml.a</code>, and <code>libcmocka.a</code>)</li> <li>Create an E3SM case. Currently, the coupled model has been tested for a case with <code>--comspet RMOSGPCC --res MOS_USRDAT</code>.</li> <li>Before building the case, make the following modifications:<ul> <li>Modify the Macros file to add settings for PETSc and RDycore</li> <li>Update the DLND streamfile (i.e <code>user_dlnd.streams.txt.lnd.gpcc</code>)</li> <li>In <code>user_nl_mosart</code>, specify a few settings for MOSART including providing a placeholder MOSART file via <code>frivinp_rtm</code></li> <li>In <code>user_nl_dlnd</code>, specify a few settings for DLND including a map from the DLND mesh to the placeholder MOSART mesh</li> </ul> </li> <li>Build the case</li> <li>Before submitting the case, do the following<ul> <li>In the rundir (<code>./xmlquerry RUNDIR</code>), copy or add symbolic links to a RDycore input YAML (as <code>rdycore.yaml</code>),  any files specified in the RDycore's YAML file (e.g. mesh, initial condition), and map file to exchange data  from the placeholder MOSART mesh to RDycore mesh.</li> <li>Change the value of <code>run_exe</code> in the <code>env_mach_specific.xml</code> to include commandline options for PETSc and libCEED.</li> </ul> </li> <li>Submit the case</li> </ol> </li> </ul> <p>The steps a-e have been automated via the shell script via <code>e3sm_rdycore_harvey_flooding.sh</code>.</p> <pre><code>cd &lt;e3sm-rdycore/externals/rdycore/docs/user/example-cases/e3sm-cases/harvey-flooding&gt;\n\n./e3sm_rdycore_harvey_flooding.sh -h\nUsage: ./e3sm_rdycore_harvey_flooding.sh\n\n   -h, --help                        Display this message\n   --e3sm-dir                        Path to E3SM-RDycore directory\n   --mach &lt;pm-cpu|pm-gpu|frontier&gt;   Supported machine name\n   --frontier-node-type &lt;cpu|gpu&gt;    To run on Frontier CPUs or GPUs\n   -N, --node  &lt;N&gt;                   Number of nodes (default = 1)\n   --project &lt;project-id&gt;            Project ID that will charged for the job\n   --rainfall_dataset &lt;name&gt;  Supported dataset name (i.e. daymet|imerg|mrms|mswep|nldas)\n</code></pre>"},{"location":"user/example-cases/e3sm-cases/harvey-flooding/e3sm_harvey.html#example-for-perlmutter-cpu-nodes","title":"Example for Perlmutter CPU nodes","text":"<pre><code>./e3sm_rdycore_harvey_flooding.sh \\\n--e3sm-dir /global/cfs/projectdirs/m4267/gbisht/e3sm/ \\\n--mach pm-cpu  \\\n-N 1 \\\n--project-id m4267 \\\n--rainfall_dataset mrms\n</code></pre>"},{"location":"user/example-cases/e3sm-cases/harvey-flooding/e3sm_harvey.html#example-for-perlmutter-gpu-nodes","title":"Example for Perlmutter GPU nodes","text":"<pre><code>./e3sm_rdycore_harvey_flooding.sh \\\n--e3sm-dir /global/cfs/projectdirs/m4267/gbisht/e3sm/ \\\n--mach pm-gpu  \\\n-N 1 \\\n--project-id m4267 \\\n--rainfall_dataset mrms\n</code></pre>"},{"location":"user/example-cases/e3sm-cases/harvey-flooding/e3sm_harvey.html#example-for-frontier-using-cpus","title":"Example for Frontier using CPUs","text":"<pre><code>./e3sm_rdycore_harvey_flooding.sh \\\n--e3sm-dir /lustre/orion/cli192/proj-shared/gb9/e3sm \\\n--mach frontier --frontier-node-type cpu \\\n-N 1 \\\n--project-id cli192 \\\n--rainfall_dataset mrms\n</code></pre>"},{"location":"user/example-cases/e3sm-cases/harvey-flooding/e3sm_harvey.html#example-for-frontier-using-gpus","title":"Example for Frontier using GPUs","text":"<pre><code>./e3sm_rdycore_harvey_flooding.sh \\\n--e3sm-dir /lustre/orion/cli192/proj-shared/gb9/e3sm \\\n--mach frontier --frontier-node-type gpu \\\n-N 1 \\\n--project-id cli192 \\\n--rainfall_dataset mrms\n</code></pre>"},{"location":"user/example-cases/harvey-flooding/harvey-flooding.html","title":"Overview","text":"<p>The RDycore mesh (<code>Turning_30m_with_z.updated.with_sidesets.exo</code>) for the Houston Harvey flooding problem is in the Exodus II format and consist of 2,926,532 grid cells. The mesh also includes a single edge sideset that consists of 13 (<code>=num_side_ss1</code>) edges, which are identified with the labels <code>elem_ss1</code> and <code>side_ss1</code> in the mesh file.</p> <p></p> <p>The topography based on the 30m DEM dataset for the study domain is shown above. The white crosses denote the locations of high water mark measurements from the USGS, and the red asterisks are the USGS gauges with the gauge number. The black dashed lines represent two dams used as flood control reservoirs: Addicks (the upper one) and Barker (the lower one). The black solid line shows the extent of major channels.</p> <p>The following two examples for the Hurricane Harvey flooding showcase different modeling capabilties of the RDycore driver:</p> <ol> <li> <p><code>critical-outflow-bc</code>:</p> <ul> <li>Uses spatially-distributed and temporally-varying rainfall dataset.</li> <li>A critical outflow boundary condition is applied on the 13 edges.</li> </ul> </li> <li> <p><code>ocean-bc</code>:</p> <ul> <li>Uses a spatially-averaged and temporally-varying rainfall dataset.</li> <li>A time-varying, but spatially-homogeneous ocean water height boundary   condition is applied on the 13 edges.</li> </ul> </li> </ol>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html","title":"Hurricane Harvey Flooding using MRMS Dataset and Critical Outflow BC","text":"<p>The 1 km Multi-Radar Multi-Sensor System (MRMS) rainfall dataset (Zhang et al., 2016), is used in this simulation. Each hourly MRMS dataset file is a PETSc Vec saved in the binary format, named as <code>YYYY-MM-DD:HH-SS.&lt;int32|int64&gt;.bin</code>. These binary files contains the following information:</p> <ul> <li><code>ncols</code>    : number of columns in the rainfall dataset</li> <li><code>nrows</code>    : number of rowns in the rainfall dataset</li> <li><code>xlc</code>      : x coordinate of the lower left corner [m]</li> <li><code>ylc</code>      : y coordinate of the lower left corner [m]</li> <li><code>cellsize</code> : size of grid cells in the rainfall dataset [m]</li> <li><code>data</code>     : rainfall rate for ncols * nrows cells [mm/hr]</li> </ul> <p>The start date and the location of MRMS dataset is specified to the RDycore driver through the following two command line options:</p> <ol> <li><code>-raster_rain_start_date YYYY,MM,DD,HH,SS</code>, and</li> <li><code>-raster_rain_dir &lt;path/to/the/mrms/dataset&gt;</code></li> </ol> <p>The MRMS dataset and mesh are available on Perlmutter and Frontier under the RDycore's project directoy. Apart from the MRMS dataset, following the four spatially-distributed rainfall datasets are also available:</p> <ol> <li>Daymet,</li> <li>North American Land Data Assimilation System (NLDAS),</li> <li>Integrated multi-satellite retrievals for global precipitation measurement (IMERG), and</li> <li>Multi-Source Weighted-Ensemble Precipitation (MSWEP)</li> </ol> <p>A critical outflow boundary condition is applied to the 13 edges within the <code>Turning_30m_with_z.updated.with_sidesets.exo</code> mesh file that are identified with the labels <code>elem_ss1</code> and <code>side_ss1</code>.</p>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html#script","title":"Script","text":"<p><code>setup_harvey_flooding_critical_outflow_bc.sh</code> Will create symbolic link to the mesh and initial condition files locally, compile RDycore (if needed), and create a batch script for DOE supercomputers that can be submitted via <code>sbatch</code>.</p> <pre><code> ./setup_harvey_flooding_critical_outflow_bc.sh -h\nUsage: ./setup_harvey_flooding_critical_outflow_bc.sh\n\n   -h, --help                        Display this message\n   --rdycore-dir                     Path to RDycore directory\n   --mach &lt;pm-cpu|pm-gpu|frontier&gt;   Supported machine name\n   --frontier-node-type &lt;cpu|gpu&gt;    To run on Frontier CPUs or GPUs\n   -N --node  &lt;N&gt;                    Number of nodes (default = 1)\n   --project &lt;project-id&gt;            Project ID that will charged for the job\n</code></pre> <ul> <li>For Perlmutter:</li> <li><code>--mach pm-cpu</code> Run RDycore on CPU nodes</li> <li><code>--mach pm-gpu</code> Run RDycore GPU nodes using CUDA</li> <li>For Frontier (<code>--mach frontier</code>):</li> <li><code>--frontier-node-type cpu</code>: Run RDycore on CPUs</li> <li><code>--frontier-node-type gpu</code>: Run RDycore on GPUs using HIP</li> </ul>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html#example-for-perlmutter-cpu-nodes","title":"Example for Perlmutter CPU nodes","text":"<pre><code>./setup_harvey_flooding_critical_outflow_bc.sh \\\n--mach pm-cpu -N 1 --project m4267 \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore\n</code></pre>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html#example-for-perlmutter-gpu-nodes","title":"Example for Perlmutter GPU nodes","text":"<pre><code>./setup_harvey_flooding_critical_outflow_bc.sh \\\n--mach pm-gpu -N 1 --project m4267_g \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore\n</code></pre>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html#example-for-frontier-using-cpus","title":"Example for Frontier using CPUs","text":"<pre><code>./setup_harvey_flooding_critical_outflow_bc.sh \\\n--mach frontier --frontier-node-type cpu -N 2 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"},{"location":"user/example-cases/harvey-flooding/critical-outflow-bc/index.html#example-for-frontier-using-gpus","title":"Example for Frontier using GPUs","text":"<pre><code>./setup_harvey_flooding_critical_outflow_bc.sh \\\n--mach frontier --frontier-node-type gpu -N 1 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html","title":"Hurricane Harvey Flooding Simulation using Spatially-homogeneous Rainfall and Time-varying Ocean BC dataset","text":"<p>Both datasets, the spatially-homogeneous rainfall (<code>share/conditions/Houston1km.rain.&lt;int32|int64&gt;.bin</code>) and time-varying ocean boundary condition (<code>share/conditions/Houston1km.bc.&lt;int32|int64&gt;.bin</code>) are PETSc <code>Vec</code> in binary format that contain the following information:</p> <pre><code>// time_1 value_1\n// time_2 value_2\n// time_3 value_3\n</code></pre> <ul> <li><code>time_*</code> has the unit of <code>seconds</code> and should start from <code>0.0</code>.</li> <li>The unit of <code>value_*</code> is<ul> <li><code>m/s</code> for the rainfall dataset, and</li> <li><code>m</code> for ocean water height boundary condition dataset.</li> </ul> </li> </ul> <p>The rainfall and boundary condition dataset can be specified to the RDycore driver through the following command line options:</p> <ol> <li><code>-rain &lt;binary-rainfall-dataset&gt;</code></li> <li><code>-homogeneous_bc_file &lt;binary-bc-dataset&gt;</code> and</li> </ol>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html#script","title":"Script","text":"<p><code>setup_harvey_flooding_ocean_bc.sh</code> Will create symbolic link to the mesh and initial condition files locally, compile RDycore (if needed), and create a batch script for DOE supercomputers that can be submitted via <code>sbatch</code>.</p> <pre><code> ./setup_harvey_flooding_ocean_bc.sh -h\nUsage: ./setup_harvey_flooding_ocean_bc.sh\n\n   -h, --help                        Display this message\n   --rdycore-dir                     Path to RDycore directory\n   --mach &lt;pm-cpu|pm-gpu|frontier&gt;   Supported machine name\n   --frontier-node-type &lt;cpu|gpu&gt;    To run on Frontier CPUs or GPUs\n   -N --node  &lt;N&gt;                    Number of nodes (default = 1)\n   --project &lt;project-id&gt;            Project ID that will charged for the job\n</code></pre> <ul> <li>For Perlmutter:</li> <li><code>--mach pm-cpu</code> Run RDycore on CPU nodes</li> <li><code>--mach pm-gpu</code> Run RDycore GPU nodes using CUDA</li> <li>For Frontier (<code>--mach frontier</code>):</li> <li><code>--frontier-node-type cpu</code>: Run RDycore on CPUs</li> <li><code>--frontier-node-type gpu</code>: Run RDycore on GPUs using HIP</li> </ul>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html#example-for-perlmutter-cpu-nodes","title":"Example for Perlmutter CPU nodes","text":"<pre><code>./setup_harvey_flooding_ocean_bc.sh \\\n --mach pm-cpu -N 1 --project m4267 \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore\n</code></pre>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html#example-for-perlmutter-gpu-nodes","title":"Example for Perlmutter GPU nodes","text":"<pre><code>./setup_harvey_flooding_ocean_bc.sh \\\n--mach pm-gpu -N 1 --project m4267_g \\\n--rdycore-dir /global/cfs/projectdirs/m4267/gbisht/rdycore \n</code></pre>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html#example-for-frontier-using-cpus","title":"Example for Frontier using CPUs","text":"<pre><code>./setup_harvey_flooding_ocean_bc.sh \\\n--mach frontier --frontier-node-type cpu -N 2 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"},{"location":"user/example-cases/harvey-flooding/ocean-bc/index.html#example-for-frontier-using-gpus","title":"Example for Frontier using GPUs","text":"<pre><code>./setup_harvey_flooding_ocean_bc.sh \\\n--mach frontier --frontier-node-type gpu -N 1 \\\n--project cli192 \\\n--rdycore-dir /lustre/orion/cli192/proj-shared/gb9/rdycore/rdycore \n</code></pre>"}]}